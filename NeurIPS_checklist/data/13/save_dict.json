{"paper_index": 18, "title": "What I Cannot Predict, I Do Not Understand: A Human-Centered Evaluation Framework for Explainability Methods", "abstract": "\n\nA multitude of explainability methods has been described to try to help users better\nunderstand how modern AI systems make decisions. However, most performance\nmetrics developed to evaluate these methods have remained largely theoretical \u2013\nwithout much consideration for the human end-user. In particular, it is not yet\nclear (1) how useful current explainability methods are in real-world scenarios;\nand (2) whether current performance metrics accurately reflect the usefulness of\nexplanation methods for the end user. To fill this gap, we conducted psychophysics\nexperiments at scale (n = 1, 150) to evaluate the usefulness of representative\nattribution methods in three real-world scenarios. Our results demonstrate that\nthe degree to which individual attribution methods help human participants better\nunderstand an AI system varies widely across these scenarios. This suggests the\nneed to move beyond quantitative improvements of current attribution methods,\ntowards the development of complementary approaches that provide qualitatively\ndifferent sources of information to human end-users.\n\n1\n\n", "introduction": "\n\nThere is now broad consensus that modern AI systems might not be safe to be deployed in the real\nworld [1] despite their exhibiting very high levels of accuracy on held-out data because these systems\nhave been shown to exploit dataset biases and other statistical shortcuts [2\u20135]. A growing body of\nresearch thus focuses on the development of explainability methods to help better interpret these\nsystems\u2019 predictions [6\u201314] to make them more trustworthy. The application of these explainability\nmethods will find broad societal uses, like easing the debugging of self-driving vehicles [15] and\nhelping to fulfill the \u201cright to explanation\u201d that European laws guarantee to its citizens [16].\n\nThe most commonly used methods in eXplainable AI (XAI) are attribution methods, but despite a\nplethora of different approaches [6\u201310, 12, 17\u201319], assessing the quality and reliability of these meth-\nods remains an open problem. So far the community has mostly focused on evaluating these methods\nusing surrogate measures defined axiomatically [15, 20\u201323]. The two most popular approaches are:\n(1) using ground truth annotations [9, 10, 12, 24\u201327] and (2) measuring faithfulness using objective\nmetrics [9, 12, 24, 25, 28, 29].\n\nThe first approach takes humans into consideration only in so far as it evaluates the alignment of\nan explanation with a human annotation. This metric assumes that the classifier relies on human-\n\n* Equal contribution \u2020 Work done while the author was working at Brown University \u2021 Work done before\n\nApril 2021 and joining Tesla\n\n36th Conference on Neural Information Processing Systems (NeurIPS 2022).\n\n\flike features*, which is an assumption that turns out to be erroneous [2\u20134], and unsurprisingly the\nresults obtained on those benchmarks do not correlate with the ability of attribution methods to help\nhumans in decision making tasks [30]. On the other hand, the second approach focuses purely on\nthe relationship between the explanations and the model, i.e., they assess whether the explanations\nactually reflect the evidence for the prediction. They have emerged as the primary means of evaluating\nattribution methods, but because they take the human out-of-the-loop of the evaluation, it is not clear\nhow well they can predict the practical usefulness of attribution methods and their possible failures.\n\nAs previously highlighted in [30], relying solely on current theoretical benchmarks to evaluate\nattribution methods can be a risky endeavor as they are totally detached from humans. Indeed, the\nseminal work of [31] has emphasized keeping in mind the end goal of XAI: to develop useful\nmethods, i.e., methods that help the user better understand their model. Thus, they recommend\nsystematically having recourse to human experiences. Moreover, a large body of research from the\npsychology literature has endorsed the argument that the functional role of explanations is to support\nlearning and generalization [32\u201338] \u2013 i.e., can an explanation help identify generalizable rules that\nreadily transfer to unseen instances? Therefore, evaluating attribution methods on their ability to help\nusers understand general rules to predict a classifier decisions is perfectly aligned with this vision.\n\nTo that end, [31] suggest evaluating explainability methods directly through the end goals of XAI.\nWe subscribe to this idea and, in this work, consider three main real-world scenarios that illustrate\npotential applications of explainability methods: (1) identifying a potential bias in a system\u2019s decision\nalong with its source using the classic Husky vs. Wolf dataset [6] (previous work has documented\nthe risk associated with a biased model [39\u201341]); (2) identifying novel strategies discovered by a\nsystem [42, 43] for tasks that would be nearly impossible for humans [44\u201347], here we consider a\nhighly complex categorization problem for non-expert humans [48, 49]; and (3) understanding failure\ncases [4, 39] on a subset of ImageNet [50].\n\nThe main contributions of this paper are as follows:\n\n\u2022 We propose a novel human-centered explainability performance measure together with associated\npsychophysics methods to experimentally evaluate the practical usefulness of modern explainability\nmethods in real-world scenarios.\n\n\u2022 Large-scale psychophysics experiments (n = 1, 150) revealed that SmoothGrad [8] is the most\nuseful attribution method amongst all tested and that none of the faithfulness performance metrics\nappear to predict if and when attribution methods will be of practical use to a human end-user.\n\u2022 Perceptual scores derived from attribution maps, characterizing either the complexity of an expla-\nnation or the challenge associated with identifying \u201cwhat\u201d features drive the system\u2019s decision,\nappear to predict failure cases of explainability methods better than faithfulness metrics.\n\n", "methods": "\n\nBefore providing a rigorous definition of interpretability, let us motivate our approach with an\nexample: a linear classifier is often considered to be readily interpretable because its inner working is\nsufficiently intuitive that it can be comprehended by a human user. A user can in turn build a mental\nmodel of the classifier \u2013 predicting the classifier\u2019s output for arbitrary inputs. In essence, we suggest\nthat the model is interpretable because the output can be predicted \u2013 i.e, we say we understand the\nrules used by a model, if we can use those inferred rules to correctly predict its output. This concept\nof predicting the classifier\u2019s output is central to our approach and we conceptualize the human user as\na Meta-predictor of the machine learning model. This notion of Meta-predictor is also closely related\nto the notion of simulatability [24, 31, 61, 65, 66]. We will now define the term more formally.\n\nWe consider a standard supervised learning setting where f is a black-box predictor that maps an\ninput x \u2208 X (e.g., an image) to an output f (x) \u2208 Y (e.g., a class label). One of the main goals\nof eXplainable AI is to yield useful rules to understand the inner-working of a model f such that\nit is possible to infer its behavior on unseen data points. To correctly infer those rules, the usual\napproach consists in studying explanations (from Attribution Map, Concept Activation Vectors,\nFeature Visualization, etc..) for several predictions. Formally, \u03a6 is any explanation functional which,\ngiven a predictor f and a point x, provides an information \u03a6(f , x) about the prediction of the\npredictor. In our experiments, \u03a6 is an attribution method but we would like to remind that the\nframework is naturally adaptable to other explainability methods such as concept-based methods or\nfeature visualization.\n\nThe understandability-completeness trade-off Different attribution methods will typically pro-\nduce different heatmaps \u2013 potentially highlighting different image regions and/or presenting the same\ninformation in a different format. The quality of an explanation can thus be affected by two factors:\nfaithfulness of the explanation (i.e., how many pixels or input dimensions deemed important effec-\ntively drive the classifier\u2019s prediction) and the understandability of the explanation for an end-user\n(i.e., how much of the pattern highlighted by the explanation is grasped by the user).\n\nAt one extreme, an explanation can be entirely faithful and provide all the information necessary to\npredict how a classifier will assign a class label to an arbitrary image (i.e., by giving all the parameters\nof the classifiers). However, such information will obviously be too complex to be understood by a\nuser and hence it is not understandable. Conversely, an explanation that overly simplifies the model\nmight offer an approximation of the rule used by the model that will be more easily grasped by the\nuser \u2013a more understandable explanation\u2013 but this approximation might ultimately mislead the user\nif it is not faithful. That is to say, just because a human agrees with the evidence pointed out by an\nexplanation does not necessarily mean that it reflects how the model works.\nOverall, this means that there is a trade-off between the amount of information provided by an\nexplanation and its comprehensibility to humans. The most useful explanations should lie somewhere\nin the middle of this trade-off.\n\n4\n\n\fThe usefulness metric We describe a new human-centered measure that incorporates this trade-off\ninto a single usefulness measure by empirically evaluating the ability of human participants to learn\nto \u201cpredict the predictor\u201d, i.e., to be an accurate Meta-predictor. Indeed, if an explanation allows\nusers to infer precise rules for the functioning of the predictor on past data, the correct application of\nthese same rules should allow the user to correctly anticipate the model\u2019s decisions on future data.\nScrutable but inaccurate explanations will result in an inaccurate Meta-predictor \u2013 just like accurate\ninscrutable ones. This Meta-predictor framework avoids current pitfalls such as confirmation bias\n- just because a user likes the explanation does not mean they will be a better Meta-predictor - or\nprediction leakage on the explanation - in simulatability experiments, as the explanation is available\nduring the test phase, any explanation that leaks the prediction would have a perfect score, without\ngiving us any additional information about the model. We will now formally describe the metric build\nusing this framework.\nWe assume a dataset\u2020 D = {(xi, f (xi), \u03a6(f , xi)}K\ni=1 used to train human participants to learn to\npredict a classifier\u2019s output f from K samples made of an input image xi, the associated predictions\nf (xi) and explanations \u03a6(f , xi). We denote \u03c8(K) a human Meta-predictor after being trained on\nthe dataset D (see Fig. 2) using explanations. In addition, let \u03c8(0) be the human Meta-predictor after\nparticipants were trained on the same dataset but without explanations to offer baseline accuracy\nscores. We can now define the usefulness of an explainability method \u03a6 after training participants\non K samples through the accuracy score of the Meta-predictor normalized by the baseline Meta-\npredictor accuracy:\n\nUtility-K =\n\nP(\u03c8(K)(x) = f (x))\nP(\u03c8(0)(x) = f (x))\n\n(1)\n\nwith P(\u00b7) the probability over a test set. Thus, Utility-K score measures the improvement in accuracy\nthat the explanation has brought. It is important to emphasize that this Utility measure only depends\non the classifier prediction and not on the ground-truth label as recommended by [67]. After fixing\nthe number of training samples K, we compare the normalized accuracy of different Meta-predictors.\nThe Meta-predictor with the highest score is then the one whose explanations were the most useful as\nmeasures compared to a no-explanation baseline.\n\nIn practice, we propose to vary the number of observations K \u2208 {K0, ..., Kn} and\nUtility metric\nto report an aggregated Utility score by computing the area under the curve (AUC) of the Utility-K.\nThe higher the AUC the better the corresponding explanation method is. Formally, given a curve\nrepresented by a set of n points C = {(K0, Utility-K 0), ..., (Kn, Utility-K n)} where Ki\u22121 < Ki\nwe define the metric as Utility = AU C(C).\n\n", "experiments": "\n\nWe first describe how participants were enrolled in the study, then our general experimental design\n(See SI for more informations).\n\nParticipants Behavioral data were gathered from n = 1, 150 participants using Amazon Mechan-\nical Turk (AMT) (www.mturk.com). All participants provided informed consent electronically\nand were compensated $1.4 for their time (\u223c 5 \u2212 8 min). The protocol was approved by the Univer-\nsity IRB and was carried out in accordance with the provisions of the World Medical Association\nDeclaration of Helsinki. For each of the three tested datasets, we ensured that there was a sufficient\nnumber of participants after filtering out uncooperative participants (n = 240 participants, 30 per\ncondition, 8 conditions) to guarantee sufficient statistical power (See SI for details). Overall, the cost\nof evaluating one method using our benchmark is relatively modest ($50 per test scenario).\n\nGeneral study design It included 3 conditions: an experimental condition where an explanation is\nprovided to human participants during their training phase (see Fig. 2), a baseline condition where\nno explanation was provided to the human participants, and a control condition where a bottom-up\nsaliency map [68] was provided as a non-informative explanation. This last control is critical, and\nindeed lacking from previous work [6, 61], because it provides a control for the possibility that\n\n\u2020We note that, in this paper, we only considered binary dataset \u2013Class 1 vs Class 2\u2013 because having the\nparticipants classify more than 2 classes would increase their cognitive load and bring unnecessary difficulty to\nthe task. Nonetheless, any dataset could have been used as classification problems with more than 2 classes can\nalways be trivially reformulated as Target class vs. Other / binary classification problems, instead of Class 1 vs\nClass 2, without lack of generality.\n\n5\n\n\fMethod\nSession n\u25e6\n\nBaseline\nControl\n\nSaliency [17]\nInteg.-Grad. [7]\nSmoothGrad [8]\nGradCAM [10]\nOcclusion [18]\nGrad.-Input [69]\n\nHusky vs. Wolf\n\nLeaves\n\nImageNet\n\n1\n\n55.7\n53.3\n\n53.9\n67.4\n68.7\n77.6\n71.0\n65.8\n\n2\n\n66.2\n61.0\n\n69.6\n72.8\n75.3\n85.7\n75.7\n63.3\n\n3\n\nUtility\n\n1\n\n62.9\n61.4\n\n73.3\n73.2\n78.0\n84.1\n78.1\n67.9\n\n0.95\n\n1.06\n1.15\n1.20\n1.34\n1.22\n1.06\n\n70.1\n72.0\n\n83.2\n82.5\n83.0\n81.9\n78.8\n76.5\n\n2\n\n76.8\n78.0\n\n88.7\n82.5\n85.7\n83.5\n86.1\n82.9\n\n3\n\nUtility\n\n1\n\n78.6\n80.2\n\n82.4\n85.3\n86.3\n82.4\n82.9\n79.5\n\n1.02\n\n1.13\n1.11\n1.13\n1.10\n1.10\n1.05\n\n58.8\n60.7\n\n61.7\n59.4\n50.3\n54.4\n51.0\n50.0\n\n2\n\n62.2\n59.2\n\n60.2\n58.3\n55.0\n52.5\n60.2\n57.6\n\n3\n\nUtility\n\n58.8\n48.5\n\n58.2\n58.3\n61.4\n54.1\n55.1\n62.6\n\n0.94\n\n1.00\n0.98\n0.93\n0.90\n0.92\n0.95\n\nTable 1: Utility-K and Utility scores. Utility-Kscores across the 3 sessions for each attribution\nmethod, for each of the 3 datasets considered, followed by the Utility scores. Higher is better. The\nUtility scores of attribution methods that are statistically significant are bolded.\n\nproviding explanations along with training images simply increases participants\u2019 engagement in the\ntask. As we will show in Sec. 5, such non-informative explanations actually led to a decrease in\nparticipants\u2019 ability to predict the classifier\u2019s decisions \u2013 suggesting that giving a wrong explanation\nis worse than giving no explanations at all.\nEach participant was only tested on a single condition to avoid possible experimental confounds. The\nmain experiment was divided into 3 training sessions (with 5 training samples in each) each followed\nby a brief test. In each individual trial, an image was presented with the associated prediction of the\nmodel, either alone for the baseline condition or together with an explanation for the experimental\nand control condition. After a brief training phase (5 samples), participants\u2019 ability to predict the\nclassifier\u2019s output was evaluated on 7 new samples during a test phase. During the test phase, no\nexplanation was provided to limit confounding effects: one possible effect is if the explanation leaks\ninformation about the class label.\u2021 We also propose to use a reservoir that subjects can refer to during\nthe testing phase to minimize memory load as a confounding factor which was reported in [61] (see\nSI for an illustration).\n\nDatasets and models We performed three distinct experiments in total \u2013 using a variety of neural\nnetwork architectures and 6 representative attributions methods. Each of these experiments aimed at\ntesting the usefulness of the explanation in a different context.\nOur first scenario focuses on the detection of biases in AI systems using the popular Wolf vs.\nHusky dataset from [6] where an evaluation measure was already proposed around the usefulness of\nexplanations for humans to detect biases. This makes it a good control experiment to measure the\neffectiveness of the framework proposed in Sec. 3. For this first experiment, we used the same model\nas in the original paper: InceptionV1 [70], and a similar dataset of Husky and Wolf images to bias\nthe model. In this situation where prior knowledge of subjects can affect their Meta-predictor score,\nwe balance data correctness (50% of correct/incorrect examples shown). Therefore, a subject relying\nonly on their prior knowledge will end up as a bad Meta-predictor of the model. For this experiment,\nthe results come from n = 242 subjects who all passed our screening process.\n\nIn our second scenario, we focus on a representative challenging image categorization task which\nwould be hard to solve by a non-expert untrained human participant and the goal is for the end-user\nto understand the strategy that was discovered by the AI system. Here, we chose the leaf dataset\ndescribed in [48]. We selected 2 classes from this dataset (Betulaceae and Celastracea) that could\nnot be classified by shape to reduce the chances that participants will discover the solution on their\nown \u2013 forcing them instead to rely on non-trivial features highlighted by the explanations (veins,\nleaf margin, etc). This scenario is far from being artificial as it reflects a genuine problem for the\npaleobotanist [49]. Can explainability methods help non-specialists discover the strategies discovered\nby an AI system? As participants are lay people from Amazon Mechanical Turk we do not expect\nthem to be experts in botany, therefore we did not explicitly try to control for prior knowledge. In this\nexperiment, n = 240 subjects passed all our screening and other filtering processes.\n\n\u2021Imagine an attribution method that would solely encode the classifiers\u2019 prediction. Participants would be\nable to guess the classifier\u2019s prediction perfectly from the explanation but the explanation per se would not help\nparticipants understand how the classifier works.\n\n6\n\n\fFigure 3: Utility-K for both Husky vs. Wolf (left) and the Leaves (right) dataset. The Utility-K of\nthe explanation, or the accuracy of the human Meta-predictor after training, is measured after each\ntraining session (3 in total) for the scenario (1) of bias detection (on the left) and the scenario (2)\nconcerning the identification of new strategies. Concerning the first scenario, all methods have a\npositive effect on the score obtained - they improve the subjects\u2019 ability to predict the model - and are\nthus useful to better understand the model. Grad-CAM, Occlusion and SmoothGrad are particularly\nuseful for bias detection. On the Leaves dataset [48], explanations are also useful, but specifically\nSaliency, SmoothGrad and Integrated Gradients.\n\nFinally, our last scenario focuses on identifying cases where an AI system fails\u00a7 using ImageNet [50],\nalso used in previous explainability work [12, 24, 30, 51, 59, 71]. We used this dataset because we\nexpect it to be representative of real-world scenarios where it is difficult to understand what the model\nrelies on for classification which makes it very difficult to understand these failure cases. Moreover,\nprevious work has pointed out that attribution methods are not useful on this dataset [59], we have\nthus chosen to extend our analysis to this particular case. We use a ResNet50 [72] pretrained on this\ndataset as predictor. Because prior knowledge is a major confounding factor on ImageNet, we select\na pair of classes that was heavily miss-classified by the model, to be able to show subjects 50% of\ncorrect/incorrect predictions: the pair Kit Fox and Red Fox fits this requirement. In this experiment,\nwe analyzed data from n = 241 participants who passed our screening and filtering processes.\n\nFor all experiments, we compared 6 representative attribution methods: Saliency (SA) [17], Gradient\n\u2299 Input (GI) [19], Integrated Gradients (IG) [7], Occlusion (OC) [18], SmoothGrad (SG) [8] and\nGrad-CAM (GC) [10]. Further information on these methods can be found in SI. Table 1 summarizes\nall the results from our psychophysics experiments.\n\n5 Results\n\nScenario (1): Bias detection Fig. 3 shows the Utility-K scores for each method after different\nnumbers of training samples were used to train participants for the biased dataset of Husky vs. Wolf.\nThe Utility score encodes the quality of the explanations provided by a method, the higher the score,\nthe better the method, with the baseline score being 1 (every score is divided by the baseline score\ncorresponding to human accuracy after training without explanations).\nA first observation is that the explanations have a positive effect on the Utility-K score: the explanation\nallows participants to better predict the model\u2019s decision (as the Utility scores are above 1). These\nresults are consistent with those reported in [6]. This is confirmed with an Analysis of Variance\n(ANOVA) for which we found a significant main effect, with a medium effect size (F (7, 234) =\n9.19, p < .001, \u03b72 = 0.089). Moreover, the only score below the baseline is that of the control\nexplanation, which do not make use of the model. We further explore our results by performing\npairwise comparisons using Tukey\u2019s Honestly Significant Difference [73] to compare the different\nexplanations against the baseline. We found 3 explainability methods to be significantly better than\nthe baseline: Grad-CAM (p < 0.001), Occlusion (p = 0.01) and SmoothGrad (p = 0.034). Thus,\nparticipants who received the Grad-CAM, Occlusion or SmoothGrad explanations performed much\nbetter than those who did not receive them.\n\n\u00a7We acknowledge the existence of some overlap between the scenario 1 and scenario 3 as bias detection is a\nspecial case of a failure case. The reason we still use scenario 1 is because of the work previously done on it,\nallowing us to validate our framework.\n\n7\n\n\fScenario (2): Identifying an expert strategy\nIn Fig. 3, we show results on the Leaves dataset. An\nANOVA analysis across all conditions revealed a significant main effect, albeit small (F (7, 232) =\n4.29, p < .001, \u03b72 = 0.042). This implies that explanation also had a positive effect resulting in\nbetter Meta-predictor in this use case. A Tukey\u2019s Honestly Significant Difference test suggests that\nthe best explanations are Saliency , SmoothGrad and Integrated Gradients as they are the only ones to\nbe significantly better than our baseline (WE) (p = .004, p = .007 and p = .03 respectively). An\ninteresting result is that SmoothGrad seems to be consistently useful across both use cases where\nexplanations are indeed practically useful. A more surprising result is that Saliency which was one of\nthe worst explanations for bias detection, is now the best explanation on this use case (We discuss\npossible reasons in SI).\n\nScenario (3): Understanding failure cases Table 1 shows that, on the ImageNet dataset, none\nof the methods tested exceeded baseline accuracy. Indeed, the experiment carried out, even with\nan improved experimental design, led us to the same conclusion as previous works [59]: none of\nthe tested attribution methods are useful (ANOVA: F (7, 233) = 1.26, p > .05). In the use case of\nunderstanding failure cases on ImageNet, no attributions methods seem to be useful.\n\nWhy do attribution methods fail?\n\nAfter studying the usefulness of attribution methods across 3 real-world scenarios for eXplainable\nAI, we found that attribution methods help, sometimes, but not always. We are interested in better\nunderstanding why sometimes attribution methods fail to help. Because this question has yet to be\nproperly studied, there is no consensus if we can still make attribution methods work on those cases\nwith incremental quantitative improvements. In the follow-up sections we explore 3 hypothesis to\nanswer that question.\n\nFaithfulness as a proxy for Utility? Faithfulness\nis often described as one of the key desiderata for\na good explanation [23, 74, 75]. If an explanation\nfails to be sufficiently faithful, the rules it highlights\nwon\u2019t allow a user to understand the inner-working of\nthe model. Thus, a lack of faithfulness on ImageNet\ncould explain our results. To test this hypothesis, we\nuse the faithfulness metrics: Deletion[9, 28], com-\nmonly used to compare attribution methods [9, 12, 24,\n25, 28, 29]. A low Deletion score indicates a good\nfaithfulness, thus for ease of reading we report the\nfaithfulness score as 1\u2212 Deletion such that a higher\nfaithfulness score is better.\n\nFigure 4: Utility vs Faithfulness correlation.\nThe results suggest that current faithfulness\nmetrics are poor predictors of the end-goal\nusefulness of explanation methods. Concern-\ning the ImageNet dataset (triangle marker),\nthe Utility scores are insignificant since none\nof the methods improves the baseline.\n\nFig 4 shows the linear relationship between our Util-\nity metrics and the faithfulness scores computed for\nevery attribution method across all 3 datasets. We\nobserve two main trends: 1) There does not appear\nto be any specific pattern regarding faithfulness\nthat could explain why attribution methods are\nnot useful for ImageNet, and 2) the least useful at-\ntribution methods for both use cases for which methods help (Bias and Leaves) are some of the\nleading methods in the field measured by the faithfulness metric. We also found a weak, if maybe\nanti-correlated, relation between faithfulness and usefulness: just focusing on making attribution\nmethods more faithful does not translate to having methods with higher practical usefulness for end-\nusers. And, in fact, focusing too heavily on faithfulness seem to come at the expense of usefulness,\nresulting in explanations that are counter-intuitively less useful. This second observation may seems\nrather alarming for the field given that the faithfulness measure is one of the driving benchmarks.\n\nAre explanations too complex? Using the trade-off between completeness and understandability\npreviously discussed in Section 3, we formulate another hypothesis: some explanations may be\nfaithful but too complex and therefore cannot be understood by humans. In that view, an explanation\nwith low complexity would tend to be more useful.\n\nAs a simple measure of the complexity of visual explanations, it would be ideal to be able\nIt was shown in previ-\nto compute the Kolmogorov complexity [76] of each explanation.\n\n8\n\n\fous work [77] to correlate well with human-derived ratings for the complexity of natural im-\nages [78, 79]. As suggested by [76, 80] we used a standard compression technique (JPEG)\nto approximate the Kolmogorov complexity. Fig. 5 shows the Utility vs complexity score of\nattribution methods for each dataset. For one of the datasets where attribution methods help,\nthe results suggest the presence of a strong correlation between usefulness and complexity:\nthe least complex method is the most useful to end-users. For the other datasets, the results\nare either not conclusive (Leaves), or are not relevant as methods are not useful (ImageNet).\nOverall, across datasets there is no significant dif-\nference in the complexity of explanations that can\nexplain why attribution methods do not help on Ima-\ngeNet. This could be because the Kolmogorov Com-\nplexity does not perfectly reflect human visual com-\nplexity, or because this is not the key element to\nexplain failure cases of attribution methods.\n\nAn intrinsic limitation of Attribution methods?\nThe role of attribution methods is to help identify\n\u201cwhere\u201d to look in an image to understand the ba-\nsis for a system\u2019s prediction. However, attribution\nmethods do not tell us \u201cwhat\u201d in those image re-\ngions is driving decisions. For categorization prob-\nlems which involve perceptually similar classes (such\nas when discriminating between different breeds of\ndogs) and fine-grained categorization problems more\ngenerally, simply looking at diagnostic image regions tells the user very little about the specific\nshape property being relevant. For instance, knowing that the ear shape is being used for recog-\nnition does not say what specific shape feature is being encoded (e.g., pointed vs.\nround or\nnarrow vs. broad base, etc). Our main hypothesis is that such a lack of explicit \u201cwhat\u201d infor-\nmation is precisely what is driving the failure of attribution methods on our ImageNet use-case.\n\nFigure 5: Utility vs Complexity correlation.\nThis suggest a weak but possibly existing link\nbetween Complexity and Utility scores.\n\nTo test this hypothesis, we estimated the percep-\ntual similarity between classes measured within di-\nagnostic regions (see SI for more details) using the\nLearned Perceptual Image Patch Similarity (LPIPS)\nmetric [81] as it has been shown to approximate hu-\nman perceptual similarity judgments well [81, 82].\nWe report the perceptual similarity score as 1 - LPIPS\nscore so that a high score means a high similarity.\nFig. 6 shows the correlation between the perceptual\nsimilarity scores vs. our Utility scores on all methods\nand datasets studied. Our results suggest a strong cor-\nrelation between perceptual similarity and practical\nusefulness: the more perceptually similar discrim-\ninative features of both classes are, the less useful\nattribution methods become. More importantly, the\nresults across datasets show that on ImageNet, where\nattribution methods do not help, every method has a\nhigh similarity score. This result suggests that after a\ncertain threshold of perceptual similarity, attribu-\ntion methods might no longer be useful, no matter\nhow faithful or low in complexity the explanation\nis. Overall, the results suggest that the perceptual similarity of discriminative features could explain\nwhy attribution methods fail on ImageNet.\n\nFigure 6: Perceptual Similarity scores vs.\nUtility. The perceptual similarity of high-\nlighted regions by a given attribution method\nfor both classes is measured, for each method,\nfor each dataset. We observe a strong cor-\nrelation between the perceptual similarity of\nfeatures highlighted for both classes and the\npractical usefulness of methods.\n\n", "conclusion": "\n\nIn summary, we conducted a large-scale human psychophysics experiment to test the utility of\nexplainability methods in real-world scenarios. Our work shows that in two of the three tested\nscenarios (bias detection and identification of new strategies), explainability methods have indeed\n\n9\n\n\fprogressed and they provide meaningful assistance to human end-users. Nevertheless, we identified a\nscenario (understanding failure case) for which none of the tested attribution methods were helpful.\nThis result is consistent with previous work [59] and highlights a fundamental challenge for XAI.\n\nFurther analysis of associated faithfulness performance metrics driving the development of explain-\nability methods revealed that they did not correlate with our empirical measure of utility \u2013 suggesting\nthat they might not be suited anymore to move the field forward. We also investigated the possibility\nthat the complexity of individual explanations may play a role in explaining human failures to learn to\nleverage those explanations to understand the model and, while we found a weak correlation between\ncomplexity and our empirical measure of utility, this correlation appears too low to explain the failure\nof these methods.\n\nFinally, because attribution methods appear to be just as faithful and low in complexity whether\nthey are useful or not, we explored the possibility that their failure lies, not in the quality of their\nexplanations, but in the intrinsic limitations of attribution methods. If fully grasping the strategy of a\nmodel requires understanding, not just \u201cwhere\u201d to look (as revealed by attribution maps) but also\n\u201cwhat\u201d to look at, something not currently revealed by these methods, attribution methods will not\nhelp. Our assumption is that the need for finer \u201cwhat\u201d information should arise when diagnostic\nimage locations across classes look perceptually very similar and potentially semantically related for\ncertain classification problems (e.g., looking at the ears or the snout to discriminate between breeds\nof cats and dogs) and one needs to identify what visual features are driving decisions. We computed a\nperceptual score for classification problems by estimating the perceptual similarity between diagnostic\nimage regions (as predicted by attribution methods) and found that, indeed, when this score predicts\na certain level of perceptual similarity between classes, attribution methods fail to contribute useful\ninformation to human users, regardless of the faithfulness or complexity of the explanations. This\nsuggests that explainability methods may need to communicate additional information to the end user\nbeyond attribution maps.\n\n7 Limitation and broader impact\n\nLimitations. Our definition of the usefulness of an explanation is quite general. However, there\nare several limitations associated with our approach to estimate usefulness. First, our approach does\nnot take into account the level of machine learning expertise of the user (the most useful explanation\nfor a novice might not be the best one for an expert). Second, the need for human participants to\nevaluate explanations brings challenges compared with the automated metrics currently used in the\nfield. However, by releasing all our data and software \u00b6, we hope to encourage the adoption of the\napproach to evaluate future explainability methods and to assess the overall progress towards the\ndevelopment of more human-interpretable AI systems.\n\nBroader impacts. While the increasing use of AI in real-world scenarios has shown potential to do\ngood [46\u201348], it has also shown its potential for harm, especially when models rely on shortcuts (e.g.,\nrelying on spurious correlations in the training set that leads to unintended racial bias [39\u201341]). To\nidentify such shortcuts, the field of Explainable AI has developed a lot of explainability methods;\nbut it is not always clear which one performs best when trying to understand a model. We hope our\nevaluation method can help in this regard, assisting the AI practitioner in better identifying bias and\nshortcuts that may unfairly discriminate against groups of people.\n\nAcknowledgments\n\nThis work was conducted as part the DEEL|| project. It was funded by ONR grant (N00014-19-\n1-2029), NSF grant (IIS-1912280 and EAR-1925481), and the Artificial and Natural Intelligence\nToulouse Institute (ANITI) grant #ANR19-PI3A-0004. The computing hardware was supported\nin part by NIH Office of the Director grant #S10OD025181 via the Center for Computation and\nVisualization (CCV) at Brown University. J.C. has been partially supported by funding from the\nValencian Government (Conselleria d\u2019Innovaci\u00f3, Universitats, Ci\u00e8ncia i Societat Digital) by virtue of\na 2022 grant agreement (convenio singular 2022).\n\n\u00b6github.com/serre-lab/Meta-predictor\n||https://www.deel.ai/\n\n10\n\n\f", "appendix": "A Human experiments\n\nA.1 Experimental design\n\nFigure 1 summarizes the experimental design used for our experiments. The participants that went\nthrough our experiments are users from the online platform Amazon Mechanical Turk (AMT).\nThrough this platform, users stay anonymous, hence, we do not collect any sensitive personal\ninformation about them. We prioritized users with a Master qualification (which is a qualification\nattributed by AMT to users who have proven to be of excellent quality) or normal users with high\nqualifications (number of HIT completed = 10000 and HIT accepted > 98%).\n\nBefore going through the experiment, participants are asked to read and agree to a consent form,\nwhich specifies: the objective and procedure of the experiment, as well as the time expected to\ncompletion (\u223c 5 - 8 min) with the reward associated ($1.4), and finally, the risk, benefits, and\nconfidentiality of taking part in this study. There are no anticipated risks and no direct benefits for the\nparticipants taking part in this study.\n\nFigure 1: Experimental design. First, every participant goes through a practice session (fig 2) to\nmake sure they understand how to use attribution methods to infer the rules used by a model, and\na quiz (fig 3) to make sure they actually read and understand the instructions. Then, participants\nare split into the different conditions \u2013 every participant will only go through one condition. The\n3 possible conditions are: an Explanation condition where an explanation is provided to human\nparticipants during their training phase, a Baseline condition where no explanation was provided to\nthe human participants, and a Control condition where a non-informative explanation was provided.\nThe main experiment was divided into 3 training sessions each followed by a brief test. In each\nindividual training trial, an image was presented with the associated prediction of the model, either\nalone for the baseline condition or together with an explanation for the experimental and control\ncondition. After a brief training phase (5 samples), participants\u2019 ability to predict the classifier\u2019s\noutput was evaluated on 7 new samples (only the image, no explanation) during a test phase. To filter\nout uncooperative participants we also add a catch trial (fig 4) in each test session.\n\nControlling for prior class knowledge To control for users\u2019 own semantic knowledge, we balanced\nthe samples shown to participants so that the classifiers were correct/incorrect 50% of the time. This\nway, the baseline (participants who try to simply predict the true class label of an image as opposed to\nlearning to predict the model\u2019s outputs) is at 50%. Any higher score reflects a certain understanding\nof the rules used by the model.\n\nA.2 Pruning out uncooperative participants\n\n3-stage screening proccess. To prune out uncooperative participants, we subjected them to a 3-stage\nscreening process. First, participants completed a short practice session to make sure they understood\nthe task and how to use the attribution methods to infer the rules used by the model (fig 2). Second,\nas done in [1], we asked participants to answer a few questions regarding the instructions provided to\nmake sure they actually read and understood them (fig 3). Third, during the main experiment, we\ntook advantage of the reservoir to introduce a catch trial (fig 4). The reservoir is the place where we\nstore the training example of the current session, which can be accessed during the testing phase.\nWe added a trial in the testing phase of each session where the input image corresponded to one of\n\n1\n\n\fFigure 2: Practice session. Through a practice session, which is a simplified version of the main\nexperiment, we evaluate if users understand how to read and use explanations. Participants that failed\nto predict correctly any of the 5 cat test images on the first try were excluded from further analysis.\n\nthe training samples used in the current session: since the answer is still on the screen (or a scroll\naway) we expect participants to be correct on these catch trials. Participants that failed any of the 3\nscreening processes were excluded from further analysis.\n\n2\n\n\fFigure 3: Quiz. Through a quiz, we make sure that users read and understood the instructions.\nParticipants that did not answer correctly every question on the first try were excluded from further\nanalysis.\n\nA.3 More results\n\nReaction time. We explored whether the usefulness of a method is reflected in the reaction time\nof participants -i.e., the more useful the explanation the faster the participants are able to grasp the\nstrategy of the model-. Table 1 shows the reaction time of participants across methods, across datasets.\nWe do not find any trend linking reaction time with usefulness.\n\nMethod\n\nHusky vs. Wolf\n\nLeaves\n\nImageNet\n\nSaliency [2]\nInteg.-Grad. [3]\nSmoothGrad [4]\nGradCAM [5]\nOcclusion [6]\nGrad.-Input [7]\n\n207.7\n213.1\n215.8\n168.9\n221.2\n210.4\n\n212.9\n216.5\n268.8\n154.6\n229.2\n238.1\n\n202.3\n218.5\n243.9\n268.9\n274.4\n208.0\n\nTable 1: Average total time per method per dataset (in second). For each dataset, we bold the\nmost useful method, and we underline the least useful method.\n\n3\n\n\fFigure 4: Catch trial. We use a reservoir (to store all the examples of the current training session)\nthat participants can refer to during the testing phase to minimize memory load. At the top of the\nscreen is the reservoir, at the bottom of the screen is a trial from the testing phase. We take advantage\nof the reservoir to introduce a catch trial. We added a trial in the testing phase of each session where\nthe input image corresponded to one of the training samples used in the current session: since the\nanswer is still on the screen (or a scroll away) we expect participants to be correct on these catch\ntrials. Participants that failed any of the 3 catch trials (one per session) were excluded from further\nanalysis.\n\n4\n\n\fB Why do the best methods for the use cases Bias detection and Identifying\n\nan expert strategy (leaves) differ?\n\nThe most interesting case is Saliency, which is the worst method on the bias dataset but the best\non the \u201cleaves\u201d dataset. On the bias dataset, the model seems to focus on the background (i.e., a\ncoarse feature), and on the \u201cleaves\u201d dataset the model seems to focus either on the margin or on\nthe vein of the leaf (i.e., very fine features). We hypothesize that different methods suit different\ngranularity of features (coarse vs fine). [4] make the hypothesis that \u201cthe saliency maps are faithful\ndescriptions of what the network is doing\u201d but because \u201cthe derivative of the score function with\nrespect to the input [is] not [...] continuously differentiable\u201d, the saliency map can appear noisy.\nBecause of this local discontinuity of the gradient, a large patch of important pixels is often portrayed\nin the saliency map as a collection of smaller patches of important pixels (i.e., a coarse feature vs\nmultiple individual fine features) which can make it hard to identify if the strategy is the coarse\nfeature or a more complex interaction of the smaller features. In the bias dataset, because the model\nrelies on the background, the Saliency maps appear very noisy and the explanation ends-up not being\nuseful. We note that SmoothGrad, which proposes to fix that discontinuity, is useful. On the other\nhand, on the leaves dataset, the model uses very fine features, therefore the Saliency maps suffer less\nfrom the discontinuity, it does not appear noisy, Saliency is useful. We also note that in this case,\nSmoothGrad is not better than Saliency, which can arguably be attributed to the fact that we do not\nneed to fix the discontinuity of the gradient. Conversely, because the granularity of both Grad-CAM\n(the feature map is much smaller than image size) and Occlusion (the patch size is much bigger than\na pixel) is too high, the heatmaps they offer on the \u201cleaves\u201d dataset are too coarse to specifically\nhighlight the fine features and it seems to take more time for the subjects to pick-up on them. But on\nthe biased dataset, Grad-CAM and Occlusion are the best performing methods.\n\nC Why do attribution methods fail?\n\nC.1 Faithfulness\n\nWhile the Deletion[8] measure is the most commonly used faithfulness metric, for completeness\nwe also consider 2 others faithfulness metric available in the Xplique library[9]: Insertion[8] and\n\u00b5Fidelity[10]. Fig 5 shows the correlation between either measure and our Utility. We find them to\nbe no better predictor of the practical usefulness of attribution methods than the Deletion measure.\n\nFigure 5: Utility vs Insertion correlation & Utility vs \u00b5Fidelity correlation The results suggest that\nevery faithfulness metrics tested are poor predictors of the practical usefulness of attribution methods.\nConcerning the ImageNet dataset (triangle marker), the Utility scores are insignificant since none of\nthe methods improves the baseline.\n\nC.2 Perceptual Similarity\n\nTab 2 shows the Perceptual Similarity scores obtained for each method, on every dataset. We observe\nthat on ImageNet, where attribution methods do not help, the perceptual similarity scores are clearly\nhigher than on the two other datasets, where attribution methods help.\nFig 6 shows examples of patches for each dataset using Grad-CAM.\n\n5\n\n\fMethod\n\nHusky vs. Wolf\n\nLeaves\n\nImageNet\n\nSaliency [2]\nInteg.-Grad. [3]\nSmoothGrad [4]\nGradCAM [5]\nOcclusion [6]\nGrad.-Input [7]\n\n0.304\n0.292\n0.285\n0.241\n0.282\n0.309\n\n0.334\n0.411\n0.286\n0.312\n0.277\n0.44\n\n0.378\n0.388\n0.384\n0.38\n0.41\n0.378\n\nTable 2: Perceptual Similarity scores. The perceptual similarity of highlighted regions by a given\nattribution method for both classes is measured, for each method, for each dataset. The perceptual\nsimilarity scores that are higher than 0.378 (the minimum score on ImageNet) are bolded. Higher is\nmore similar.\n\nFigure 6: Examples of extracted patches. The perceptual similarity score is performed on the\nlocations considered most important by the attribution methods. Examples of patches extracted for\nthe three datasets with the Grad-CAM method.\n\n6\n\n\fD Attribution methods\n\nD.1 Methods\n\nIn the following section, the formulation of the different methods used in the experiment is given.\nWe define f (x) the logit score (before softmax) for the class of interest. An explanation method\nprovides an attribution score for each input variables. Each value then corresponds to the importance\nof this feature for the model results.\n\nSaliency [2] is a visualization technique based on the gradient of a class score relative to the input,\nindicating in an infinitesimal neighborhood, which pixels must be modified to most affect the score\nof the class of interest.\n\n\u03a6SA(x) = ||\u2207xf (x)||\n\nGradient \u2299 Input [7] is based on the gradient of a class score relative to the input, element-wise\nwith the input, it was introduced to improve the sharpness of the attribution maps. A theoretical\nanalysis conducted by [11] showed that Gradient \u2299 Input is equivalent to \u03f5-LRP and DeepLIFT [12]\nmethods under certain conditions: using a baseline of zero, and with all biases to zero.\n\n\u03a6GI (x) = x \u2299 ||\u2207xf (x)||\n\nIntegrated Gradients [3] consists of summing the gradient values along the path from a baseline\nstate to the current value. The baseline is defined by the user and often chosen to be zero. This\nintegral can be approximated with a set of m points at regular intervals between the baseline and the\npoint of interest. In order to approximate from a finite number of steps, we use a Trapezoidal rule and\nnot a left-Riemann summation, which allows for more accurate results and improved performance\n(see [13] for a comparison). The final result depends on both the choice of the baseline x0 and the\nnumber of points to estimate the integral. In the context of these experiments, we use zero as the\nbaseline and m = 80.\n\n\u03a6IG(x) = (x \u2212 x0)\n\n 1\n\n0\n\n\u2207xf (x0 + \u03b1(x \u2212 x0)))d\u03b1\n\nSmoothGrad [4] is also a gradient-based explanation method, which, as the name suggests, averages\nthe gradient at several points corresponding to small perturbations (drawn i.i.d from a normal\ndistribution of standard deviation \u03c3) around the point of interest. The smoothing effect induced by the\naverage helps reduce the visual noise and hence improve the explanations. In practice, Smoothgrad is\nobtained by averaging after sampling m points. In the context of these experiments, we took m = 80\nand \u03c3 = 0.2 as suggested in the original paper.\n\n\u03a6SG(x) = E\u03b5\u223cN (0,I\u03c3)(\u2207xf (x + \u03b5))\nGrad-CAM [5] can be used on Convolutional Neural Network (CNN), it uses the gradient and the\nfeature maps Ak of the last convolution layer. More precisely, to obtain the localization map for a\nc associated to each of the feature map activation Ak, with k\nclass, we need to compute the weights \u03b1k\n\u2202f (x)\nthe number of filters and Z the number of features in each feature map, with \u03b1c\n\u2202Ak\nij\nand\n\nk = 1\nZ\n\n\nj\n\n\ni\n\n\u03a6GC = max(0,\n\n\n\nkAk)\n\u03b1c\n\nNotice that the size of the explanation depends on the size (width, height) of the last feature map, a\nbilinear interpolation is performed in order to find the same dimensions as the input.\n\nOcclusion [6] is a sensitivity method that sweeps a patch that occludes pixels over the images, and\nuses the variations of the model prediction to deduce critical areas. In the context of these experiments,\nwe took a patch size and a patch stride of of 1 tenth of the image size.\n\nk\n\n\u03a6OC\n\ni = f (x) \u2212 f (x[xi=0])\n\n7\n\n\fD.2 Examples of explanations\n\nExamples of explanations from the different attributions methods evaluated through our experiments\non the Husky vs. Wolf dataset (fig 7), the Leaves dataset (fig 8) and the ImageNet dataset (fig 9).\n\nFigure 7: Examples of images from the Wolf vs. Husky experiment, alongside their respective:\nControl explanation (which is a non-informative explanation) as well as the different Attribution\nmethods evaluated in our experiment.\n\n8\n\n\fFigure 8: Examples of images from the Leaves experiment, alongside their respective: Control\nexplanation (which is a non-informative explanation) as well as the different Attribution methods\nevaluated in our experiment.\n\n9\n\n\fFigure 9: Examples of images from the ImageNet experiment, alongside their respective: Control\nexplanation (which is a non-informative explanation) as well as the different Attribution methods\nevaluated in our experiment.\n\n10\n\n\f", "system_prompts": [{"role": "system", "content": "You are a computer science researcher currently reviewing a paper titled \"What I Cannot Predict, I Do Not Understand: A Human-Centered Evaluation Framework for Explainability Methods\" for the NeurIPS computer science conference. Your goal is to try to be as objective and truthful as possible in your answers about the paper provided. Your reviews will be used for causal reasoning in determining the quality of the paper."}], "problems_dict": {"q1b": [[{"role": "user", "content": "The following is the conclusion section of the paper you are reviewing:\n\n\nOne future direction is to consider incentives in our paradigm like the literature of information\nelicitation without verification [13, 18, 5, 22, 9]. We have asked a class of students at Peking\nUniversity: why are bar chairs high? using our paradigm. We cluster the answers by hand. The\nplurality answer is \u201cthe bar counter is high\u201d and our top-ranking answer is \u201cbetter eye contact with\npeople who stand\u201d. Thus, another future diction is to extend our approach to the scenario where\npeople\u2019s answers are sentences, where we can apply NLP to cluster them automatically. In summary,\nwe propose the first empirically validated method to learn the thinking hierarchy without any prior\nin the general problem-solving scenarios. Potentially, our paradigm can be used to make a better\ndecision when we crowd-source opinions in a new field with little prior information. Moreover, when\nwe elicit the crowds\u2019 opinions for a policy, with the thinking hierarchy information, it\u2019s possible to\nunderstand the crowds\u2019 opinions better. However, regarding the negative impact, it may be easier\nto implement a social media manipulation of public opinion with the full thinking hierarchy of the\ncrowds. One interesting future direction is to explore the impact of the thinking hierarchy information.\n\n\nBased on this section, do the authors describe limitations of their work?"}]], "q1c": [[{"role": "user", "content": "The following is the conclusion section of the paper you are reviewing:\n\n\nOne future direction is to consider incentives in our paradigm like the literature of information\nelicitation without verification [13, 18, 5, 22, 9]. We have asked a class of students at Peking\nUniversity: why are bar chairs high? using our paradigm. We cluster the answers by hand. The\nplurality answer is \u201cthe bar counter is high\u201d and our top-ranking answer is \u201cbetter eye contact with\npeople who stand\u201d. Thus, another future diction is to extend our approach to the scenario where\npeople\u2019s answers are sentences, where we can apply NLP to cluster them automatically. In summary,\nwe propose the first empirically validated method to learn the thinking hierarchy without any prior\nin the general problem-solving scenarios. Potentially, our paradigm can be used to make a better\ndecision when we crowd-source opinions in a new field with little prior information. Moreover, when\nwe elicit the crowds\u2019 opinions for a policy, with the thinking hierarchy information, it\u2019s possible to\nunderstand the crowds\u2019 opinions better. However, regarding the negative impact, it may be easier\nto implement a social media manipulation of public opinion with the full thinking hierarchy of the\ncrowds. One interesting future direction is to explore the impact of the thinking hierarchy information.\n\n\nBased on this section, do the authors address potential negative societal impacts of their work?"}]], "q2a": [[{"role": "user", "content": "The following is the abstract of the paper you are reviewing:\n\n\nWhen we use the wisdom of the crowds, we usually rank the answers according to\ntheir popularity, especially when we cannot verify the answers. However, this can\nbe very dangerous when the majority make systematic mistakes. A fundamental\nquestion arises: can we build a hierarchy among the answers without any prior\nwhere the higher-ranking answers, which may not be supported by the majority,\nare from more sophisticated people? To address the question, we propose 1) a\nnovel model to describe people\u2019s thinking hierarchy; 2) two algorithms to learn\nthe thinking hierarchy without any prior; 3) a novel open-response based crowd-\nsourcing approach based on the above theoretic framework. In addition to theoretic\njustifications, we conduct four empirical crowdsourcing studies and show that a)\nthe accuracy of the top-ranking answers learned by our approach is much higher\nthan that of plurality voting (In one question, the plurality answer is supported by\n74 respondents but the correct answer is only supported by 3 respondents. Our\napproach ranks the correct answer the highest without any prior); b) our model\nhas a high goodness-of-fit, especially for the questions where our top-ranking\nanswer is correct. To the best of our knowledge, we are the first to propose a\nthinking hierarchy model with empirical validations in the general problem-solving\nscenarios; and the first to propose a practical open-response based crowdsourcing\napproach that beats plurality voting without any prior.\n\n1\n\n\nBased on this abstract, do the authors have theoretical results? Please start your answer with \"Yes\", \"No\", or \"Unsure\"."}, {"role": "user", "content": "The following is the methods section of the paper you are reviewing:\n\n\nWe first introduce our model for thinking hierarchy. Tversky and Kahneman [27] propose that people\nhave two systems, a fast and intuitive system, and a slow and logical system. For example, Alice\nstarts to solve the circle problem. When she reads the question, she can run her intuitive system 1 and\nobtain answer \u201c3\u201d. However, when she starts to think carefully, she runs her more careful system 2 to\nobtain answer \u201c4\u201d.\n\nWe propose a more general model where people can run multiple oracles to approach the question\nduring their thinking process. Conceptually similar to the cognitive hierarchy theory [3], we assume\nthe oracles have different levels. People usually run lower level oracles before the higher level oracles.\nIn the previous example, system 1 is the lower level oracle and system 2 is the higher one. We assume\nthat Alice runs system 2 after system 1. Thus, in our model, people who know the answer is \u201c4\u201d can\n\n4\n\n\fpredict that other people answer \u201c3\u201d, which is hypothesized in Kong and Schoenebeck [10]. It\u2019s also\npossible that some people run the most sophisticated oracle directly without running the lower ones.\nThus, we design the model such that it does not require the higher-type to be able to predict ALL\nlower types. We also allow the oracles\u2019 outputs to be random.\n\nSection 2.1 introduces the model of thinking hierarchy. Section 2.2 reduces the model inference\nproblem to a matrix decomposition problem. Section 2.3 and section 2.4 show how to learn the\nthinking hierarchy.\n\n2.1 Thinking hierarchy\n\nFixing a question q (e.g. the circle problem), T denotes the set of thinking types. A denotes the set of\npossible answers. Both T and A are finite sets. \u2206A denotes all possible distributions over A. We\nsometimes use \u201cprob\u201d as a shorthand for probability.\n\nGenerating answers We will describe how people of different thinking types generate answers.\nDefinition 2.1 (Oracles of thinking types W ). An answer generating oracle maps the question to\nan (random) answer in A. Each type t corresponds to an oracle Ot. The output Ot(q) is a random\nvariable whose distribution is wt \u2208 \u2206A. W denotes a |T | \u00d7 |A| matrix where each row t is wt.\nEach respondent is type t with prob pt and (cid:80)\nrunning the oracle Ot. For all a \u2208 A, the probability that a respondent answers a will be (cid:80)\nWe assume the probability is positive for all a \u2208 A.\nExample 2.2 (A running example). There are two types T = {0, 1}. The answer space is A =\n{3, 4, 6}. O0 will output \u20183\u2019 with probability 0.8 and \u20186\u2019 with probability 0.2. O1 will output \u20184\u2019\n0\n1\n\nt pt = 1. A type t respondent generates the answer by\nt ptwt(a).\n\ndeterministically. In this example, W =\n\nwhere the first row is the distribution of\n\n(cid:20)0.8\n0\n\n0.2\n0\n\n(cid:21)\n\nO0\u2019s output and the second row is the distribution of O1\u2019s output.\n\nGenerating predictions We then describe how people of different thinking types predict what other\npeople will answer. Here the prediction is not a distribution, but an answer other people may report.\nWhen a type t respondent makes a prediction, she will run an oracle, which is Ot\u2032 with probability\npt\u2192t\u2032 where (cid:80)\n\nt\u2032 pt\u2192t\u2032 = 1. She uses the output of Ot\u2032 as the prediction g \u2208 A.\n\nCombination: answer-prediction joint distribution M M denotes a |A| \u00d7 |A| matrix where\nMa,g is the probability an respondent answers a and predicts g. \u039b denotes a |T | \u00d7 |T | matrix where\n\u039bt,t\u2032 = ptpt\u2192t\u2032 is the probability a respondent is type t and predicts type t\u2032.\nExample 2.3. In this example, when type 0 respondent makes a prediction, with prob 1, she will run\nO0 again. When type 1 respondent makes a prediction, with prob 0.5, she will run O1 again, with\nprob 0.5, she will run O0. Moreover, a respondent is type 0 with prob 0.7, and type 1 with prob 0.3.\n\nHere \u039b =\n\n(cid:20)p0p0\u21920\np1p1\u21920\n\np0p0\u21921\np1p1\u21921\n\n(cid:21)\n\n=\n\n(cid:20) 0.7 \u2217 1\n0.3 \u2217 0.5\n\n0.7 \u2217 0\n0.3 \u2217 0.5\n\n(cid:21)\n\n=\n\n(cid:20) 0.7\n0.15\n\n(cid:21)\n\n.\n\n0\n0.15\n\nClaim 2.4. Based on the above generating processes, M = W\u22a4\u039bW.\n\nProof. For each respondent, the probability she answers a and predicts g will be\n(cid:88)\n\n(cid:88)\n\n(cid:88)\n\nptwt(a)\n\npt\u2192t\u2032wt\u2032(g) =\n\nwt(a)ptpt\u2192t\u2032wt\u2032(g).\n\nMa,g =\n\nt\n\nt\u2032\n\nt,t\u2032\n\nWe sum over all possible types the respondent will be. Given she is type t, she runs oracle Ot to\ngenerate the answer and wt(a) is the probability that the answer is a. We sum over all possible\noracles she runs to predict. Given that she runs Ot\u2032, wt\u2032(g) is the probability the prediction is g.\n\nKey assumption: upper-triangular \u039b we assume that people of a less sophisticated level can\nnever run the oracles of more sophisticated levels. A linear ordering of types \u03c0 : {1, 2, \u00b7 \u00b7 \u00b7 , |T |} (cid:55)\u2192 T\nmaps a ranking position to a type. For example, \u03c0(1) \u2208 T is the top-ranking type.\nAssumption 2.5. We assume that with a proper ordering \u03c0 of the types, \u039b is an upper-triangular\nmatrix. Formally, there exists \u03c0 such that \u2200i > j, \u039b\u03c0(i),\u03c0(j) = 0. Any \u03c0 that makes \u039b upper-\ntriangular is a valid thinking hierarchy of the types.\n\n5\n\n\fIn the running example, the valid thinking hierarchy is \u03c0(1) = type 1, \u03c0(2) = type 0. Note that the\nabove assumption does not require \u2200i \u2264 j, \u039b\u03c0(i),\u03c0(j) > 0. When \u039b is a diagonal matrix, types cannot\npredict each other and are equally sophisticated, thus any ordering is a valid thinking hierarchy.\n\nAn algorithm finds the thinking hierarchy when the algorithm is given M which is generated by\nlatent (unknown) W, \u039b, and the algorithm will output a matrix W\u2217 which equals a row-permuted\nW where the row order is a valid thinking hierarchy. Formally, there exists a valid thinking hierarchy\n\u03c0 such that the ith row of W\u2217 is the \u03c0(i)th row of W, i.e, w\u2217\n\ni = w\u03c0(i).\n\n2.2 Non-negative Congruence Triangularization (NCT)\n\nWith the above model, inferring thinking hierarchy leads to a novel matrix decomposition problem,\nwhich is similar to the symmetric non-negative matrix factorization problem (NMF)6. A non-negative\nmatrix is a matrix whose elements are non-negative.\nDefinition 2.6 (Non-negative Congruence7 Triangularization (NCT)). Given a non-negative matrix\nM, NCT aims to find non-negative matrices W and non-negative upper-triangular matrix \u039b such\nthat M = W\u22a4\u039bW. In a Frobenius norm based approximated version, given a set of matrices W,\nNCT aims to find non-negative matrices W and non-negative upper-triangular matrix \u039b to minimize\n\nmin\nW\u2208W,\u039b\n\n||M \u2212 W\u22a4\u039bW||2\nF\n\nand the minimum is defined as the lack-of-fit of M regarding W 8.\n\nLike NMF, it\u2019s impossible to ask for the strict uniqueness of the results. Let P\u039b be the set of\npermutation matrices such that \u03a0\u22a4\u039b\u03a0 is still upper-triangular.\nIf (W, \u039b) is a solution, then\n(\u03a0\u22121DW, \u03a0\u22a4D\u22121\u039bD\u22121\u03a0) is also a solution where D is a diagonal matrix with positive elements\nand \u03a0 \u2208 P\u039b. We state the uniqueness results as follows and the proof is deferred to Appendix C.\nProposition 2.7 (Uniqueness). If |T | \u2264 |A| and T columns of W consist of a permuted positive\ndiagonal matrix, NCT for M = W\u22a4\u039bW is unique in the sense that then for all W\u2032\u22a4\u039b\u2032W\u2032 =\nW\u22a4\u039bW, there exists a positive diagonal matrix D and a |T | \u00d7 |T | permutation matrix \u03a0 \u2208 P\u039b\nsuch that W\u2032 = \u03a0\u22121DW.\n\nWhen we restrict W to be \u201csemi-orthogonal\u201d, we obtain a clean format of NCT without searching\nfor optimal \u039b. I is the set of all \u201csemi-orthogonal\u201d matrices W where each column of W has\nand only has one non-zero element and WW\u22a4 = I. For example, the W in Example 2.2 can be\nnormalized to a semi-orthogonal matrix. The following lemma follows from the expansion of the\nFrobenius norm and we defer the proof to Appendix C.\n\nLemma 2.8 (Semi-orthogonal: minimizing F-norm = maximizing upper-triangular\u2019s sum of the\nsquare). For all set of matrices W \u2282 I, minW\u2208W,\u039b ||M \u2212 W\u22a4\u039bW||2\nF is equivalent to solv-\ni,j and setting \u039b as Up(WMW\u22a4), the upper-triangular area of\ning maxW\u2208W\nWMW\u22a4.\n\ni\u2264j(WMW\u22a4)2\n\n(cid:80)\n\n2.3\n\nInferring the thinking hierarchy with answer-prediction joint distribution M\n\nGiven M, inferring the thinking hierarchy is equivalent to solving NCT in general. Though we do not\nhave M, later we will show a proxy for M. For simplicity of practical use, we introduce two simple\nranking algorithms by employing Lemma 2.8. The ranking algorithm takes M as input and outputs a\nlinear ordering of answers \u03c0 : {1, 2, \u00b7 \u00b7 \u00b7 , |A|} (cid:55)\u2192 A that maps a ranking position to an answer.\n\nAnswer-Ranking Algorithm (Default) AR(M) The algorithm computes\n\n\u03a0\u2217 \u2190 arg max\n\u03a0\u2208P\n\n(cid:88)\n\n(\u03a0M\u03a0\u22a4)2\ni,j\n\ni\u2264j\n\n6Symmetric NMF: minW ||M \u2212 W\u22a4W||2\nF\n7We use congruence here though it is not matrix congruence since W may not be a square matrix.\n8M = W\u22a4\u039bW, W \u2208 W has zero lack-of-fit.\n\n6\n\n\fwhere P is the set of all |A| \u00d7 |A| permutation matrices. There is a one to one mapping between each\npermutation matrix \u03a0 and a linear ordering \u03c0: \u03a0i,\u03c0(i) = 1, \u2200i. Therefore, the optimal \u03a0\u2217 leads to an\noptimal rank over answers directly and the default algorithm can be also represented as\n\n\u03c0\u2217 \u2190 arg max\n\n\u03c0\n\nM 2\n\n\u03c0(i),\u03c0(j).\n\n(cid:88)\n\ni\u2264j\n\nTo find the optimal rank, we use a dynamic programming based algorithm (see the supplementary\nmaterials) which takes O(2|A||A|2). In practice, |A| is usually at most 7 or 8. In our empirical study,\nthe default algorithm takes 91 milliseconds to finish the computation of all 152 questions.\n\nThe default algorithm implicitly assumes |T | = |A| and all oracles are deterministic. To allow\n|T | < |A| and non-deterministic oracles, we introduce a variant that generalizes P to a subset of\nsemi-orthogonal matrices I. Every |T | \u00d7 |A| semi-orthogonal W indicates a hard clustering. Each\ncluster t \u2208 T contains all answers a such that Wt,a > 0. For example, the W in Example 2.2 can\nbe normalized to a semi-orthogonal matrix and indicates a hard clustering {4}, {6, 3}. Therefore,\nthe variant algorithm will partition the answers into multiple clusters and assign a hierarchy to the\nclusters.\n\nAnswer-Ranking Algorithm (Variant) AR+(M, W) The algorithm computes\n\nW\u2217 \u2190 arg max\nW\u2208I\n\n(cid:88)\n\n(WMW\u22a4)2\n\ni,j.\n\ni\u2264j\n\nwhere W \u2282 I. W\u2217 is normalized such that every row sums to 1. This algorithm does not restrict\n|T | = |A| and learns the optimal |T |.\n\nW\u2217 \u21d2 Answer rank The output W\u2217 indicates a hard clustering of all answers. We rank all answer\nas follows: for any i < j, the answers in cluster i has a higher rank 9 than the answers in cluster j.\nFor all i, for any two answers a, a\u2032 in the same cluster i, a is ranked higher than a\u2032 if W \u2217\ni,a\u2032.\n\ni,a > W \u2217\n\nTheoretical justification When M perfectly fits the model with the restriction that the latent W is\na permutation or a hard clustering, we show that our algorithm finds the thinking hierarchy. Otherwise,\nour algorithm finds the \u201cclosest\u201d solution measured by the Frobenius norm.\nTheorem 2.9. When there exists \u03a00 \u2208 P and non-negative upper-triangular matrix \u039b0 such that\n0 \u039b0\u03a00, AR(M) finds the thinking hierarchy 10. In general, AR(M) will output \u03a0\u2217 where\nM = \u03a0\u22a4\n\u03a0\u2217, \u039b\u2217 = Up(\u03a0\u2217M\u03a0\u2217\u22a4) is a solution to arg min\u03a0\u2208P,\u039b ||M \u2212 \u03a0\u22a4\u039b\u03a0||2\nF . The above statement\nis still valid by replacing P by W \u2282 I and AR(M) by AR+(M, W).\n\nProposition 2.7 and Lemma 2.8 almost directly imply the above theorem. We defer the formal proof\nto Appendix C.\n\n2.4 A proxy for answer-prediction joint distribution M\n\nIn practice, we do not have perfect M. We use the following open-response paradigm to obtain a\nproxy for M.\n\nAnswer-prediction paradigm the respondents are asked Q1: What\u2019s your answer? Answer:\nQ2: What do you think other people will answer:\n\n.\n\nIn the circle example, the possible feedback can be \u201canswer: 4; prediction: 3\u201d, \u201canswer: 3; prediction:\n6,9,1\u201d... We collect all answers provided by the respondents 11 and denote the set of them by A. In\nthe circle example, A = {1, 2, 3, 4, 6, 9}. We also allow respondents to provide no prediction or\nmultiple predictions.\n\n9Rank 1 answer is in the highest position.\n10See definition in the last paragraph in Section 2.1.\n11In practice, we set a threshold \u03b8 and collect answers which are provided by at least \u03b8 fraction of the\nrespondents. We allow multiple predictions and also allow people to answer \u201cI do not know\u201d. See Section 3 for\nmore details.\n\n7\n\n\f(a) Accuracy of algorithms\n\n(b) Empirical distribution of lack-of-fit\n\nFigure 3: The results of our experiment\n\nAnswer-prediction matrix We aggregate the feedback and visualize it by an Answer-Prediction\nmatrix. The Answer-Prediction matrix A is a |A| \u00d7 |A| square matrix where |A| is the number of\ndistinct answers provided by the respondents. Each entry Aa,g, a, g \u2208 A is the number of respondents\nthat answer \u201ca\u201d and predict \u201cg\u201d.\n\nWe will show that with proper assumptions, the answer-prediction matrix A\u2019s expectation is pro-\nportional to M. First, for ease of analysis, we assume that each respondent\u2019s predictions are i.i.d.\nsamples12. Second, since we allow people to optionally provide predictions, we need to additionally\nassume that the number of predictions each respondent is willing to provide is independent of her\ntype and answer. We state the formal result as follows and the proof is deferred to Appendix C.\n\nProposition 2.10. When each respondent\u2019s predictions are i.i.d. samples, and the number of\npredictions she gives is independent of her type and answer, the answer-prediction matrix A\u2019s\nexpectation is proportional to M.\n\n\nBased on this section, do the authors state the assumptions for their theoretical results?"}]], "q2b": [[{"role": "user", "content": "The following is the abstract of the paper you are reviewing:\n\n\nWhen we use the wisdom of the crowds, we usually rank the answers according to\ntheir popularity, especially when we cannot verify the answers. However, this can\nbe very dangerous when the majority make systematic mistakes. A fundamental\nquestion arises: can we build a hierarchy among the answers without any prior\nwhere the higher-ranking answers, which may not be supported by the majority,\nare from more sophisticated people? To address the question, we propose 1) a\nnovel model to describe people\u2019s thinking hierarchy; 2) two algorithms to learn\nthe thinking hierarchy without any prior; 3) a novel open-response based crowd-\nsourcing approach based on the above theoretic framework. In addition to theoretic\njustifications, we conduct four empirical crowdsourcing studies and show that a)\nthe accuracy of the top-ranking answers learned by our approach is much higher\nthan that of plurality voting (In one question, the plurality answer is supported by\n74 respondents but the correct answer is only supported by 3 respondents. Our\napproach ranks the correct answer the highest without any prior); b) our model\nhas a high goodness-of-fit, especially for the questions where our top-ranking\nanswer is correct. To the best of our knowledge, we are the first to propose a\nthinking hierarchy model with empirical validations in the general problem-solving\nscenarios; and the first to propose a practical open-response based crowdsourcing\napproach that beats plurality voting without any prior.\n\n1\n\n\nBased on this abstract, do the authors have theoretical results? Please start your answer with \"Yes\", \"No\", or \"Unsure\"."}, {"role": "user", "content": "The following is the methods section of the paper you are reviewing:\n\n\nWe first introduce our model for thinking hierarchy. Tversky and Kahneman [27] propose that people\nhave two systems, a fast and intuitive system, and a slow and logical system. For example, Alice\nstarts to solve the circle problem. When she reads the question, she can run her intuitive system 1 and\nobtain answer \u201c3\u201d. However, when she starts to think carefully, she runs her more careful system 2 to\nobtain answer \u201c4\u201d.\n\nWe propose a more general model where people can run multiple oracles to approach the question\nduring their thinking process. Conceptually similar to the cognitive hierarchy theory [3], we assume\nthe oracles have different levels. People usually run lower level oracles before the higher level oracles.\nIn the previous example, system 1 is the lower level oracle and system 2 is the higher one. We assume\nthat Alice runs system 2 after system 1. Thus, in our model, people who know the answer is \u201c4\u201d can\n\n4\n\n\fpredict that other people answer \u201c3\u201d, which is hypothesized in Kong and Schoenebeck [10]. It\u2019s also\npossible that some people run the most sophisticated oracle directly without running the lower ones.\nThus, we design the model such that it does not require the higher-type to be able to predict ALL\nlower types. We also allow the oracles\u2019 outputs to be random.\n\nSection 2.1 introduces the model of thinking hierarchy. Section 2.2 reduces the model inference\nproblem to a matrix decomposition problem. Section 2.3 and section 2.4 show how to learn the\nthinking hierarchy.\n\n2.1 Thinking hierarchy\n\nFixing a question q (e.g. the circle problem), T denotes the set of thinking types. A denotes the set of\npossible answers. Both T and A are finite sets. \u2206A denotes all possible distributions over A. We\nsometimes use \u201cprob\u201d as a shorthand for probability.\n\nGenerating answers We will describe how people of different thinking types generate answers.\nDefinition 2.1 (Oracles of thinking types W ). An answer generating oracle maps the question to\nan (random) answer in A. Each type t corresponds to an oracle Ot. The output Ot(q) is a random\nvariable whose distribution is wt \u2208 \u2206A. W denotes a |T | \u00d7 |A| matrix where each row t is wt.\nEach respondent is type t with prob pt and (cid:80)\nrunning the oracle Ot. For all a \u2208 A, the probability that a respondent answers a will be (cid:80)\nWe assume the probability is positive for all a \u2208 A.\nExample 2.2 (A running example). There are two types T = {0, 1}. The answer space is A =\n{3, 4, 6}. O0 will output \u20183\u2019 with probability 0.8 and \u20186\u2019 with probability 0.2. O1 will output \u20184\u2019\n0\n1\n\nt pt = 1. A type t respondent generates the answer by\nt ptwt(a).\n\ndeterministically. In this example, W =\n\nwhere the first row is the distribution of\n\n(cid:20)0.8\n0\n\n0.2\n0\n\n(cid:21)\n\nO0\u2019s output and the second row is the distribution of O1\u2019s output.\n\nGenerating predictions We then describe how people of different thinking types predict what other\npeople will answer. Here the prediction is not a distribution, but an answer other people may report.\nWhen a type t respondent makes a prediction, she will run an oracle, which is Ot\u2032 with probability\npt\u2192t\u2032 where (cid:80)\n\nt\u2032 pt\u2192t\u2032 = 1. She uses the output of Ot\u2032 as the prediction g \u2208 A.\n\nCombination: answer-prediction joint distribution M M denotes a |A| \u00d7 |A| matrix where\nMa,g is the probability an respondent answers a and predicts g. \u039b denotes a |T | \u00d7 |T | matrix where\n\u039bt,t\u2032 = ptpt\u2192t\u2032 is the probability a respondent is type t and predicts type t\u2032.\nExample 2.3. In this example, when type 0 respondent makes a prediction, with prob 1, she will run\nO0 again. When type 1 respondent makes a prediction, with prob 0.5, she will run O1 again, with\nprob 0.5, she will run O0. Moreover, a respondent is type 0 with prob 0.7, and type 1 with prob 0.3.\n\nHere \u039b =\n\n(cid:20)p0p0\u21920\np1p1\u21920\n\np0p0\u21921\np1p1\u21921\n\n(cid:21)\n\n=\n\n(cid:20) 0.7 \u2217 1\n0.3 \u2217 0.5\n\n0.7 \u2217 0\n0.3 \u2217 0.5\n\n(cid:21)\n\n=\n\n(cid:20) 0.7\n0.15\n\n(cid:21)\n\n.\n\n0\n0.15\n\nClaim 2.4. Based on the above generating processes, M = W\u22a4\u039bW.\n\nProof. For each respondent, the probability she answers a and predicts g will be\n(cid:88)\n\n(cid:88)\n\n(cid:88)\n\nptwt(a)\n\npt\u2192t\u2032wt\u2032(g) =\n\nwt(a)ptpt\u2192t\u2032wt\u2032(g).\n\nMa,g =\n\nt\n\nt\u2032\n\nt,t\u2032\n\nWe sum over all possible types the respondent will be. Given she is type t, she runs oracle Ot to\ngenerate the answer and wt(a) is the probability that the answer is a. We sum over all possible\noracles she runs to predict. Given that she runs Ot\u2032, wt\u2032(g) is the probability the prediction is g.\n\nKey assumption: upper-triangular \u039b we assume that people of a less sophisticated level can\nnever run the oracles of more sophisticated levels. A linear ordering of types \u03c0 : {1, 2, \u00b7 \u00b7 \u00b7 , |T |} (cid:55)\u2192 T\nmaps a ranking position to a type. For example, \u03c0(1) \u2208 T is the top-ranking type.\nAssumption 2.5. We assume that with a proper ordering \u03c0 of the types, \u039b is an upper-triangular\nmatrix. Formally, there exists \u03c0 such that \u2200i > j, \u039b\u03c0(i),\u03c0(j) = 0. Any \u03c0 that makes \u039b upper-\ntriangular is a valid thinking hierarchy of the types.\n\n5\n\n\fIn the running example, the valid thinking hierarchy is \u03c0(1) = type 1, \u03c0(2) = type 0. Note that the\nabove assumption does not require \u2200i \u2264 j, \u039b\u03c0(i),\u03c0(j) > 0. When \u039b is a diagonal matrix, types cannot\npredict each other and are equally sophisticated, thus any ordering is a valid thinking hierarchy.\n\nAn algorithm finds the thinking hierarchy when the algorithm is given M which is generated by\nlatent (unknown) W, \u039b, and the algorithm will output a matrix W\u2217 which equals a row-permuted\nW where the row order is a valid thinking hierarchy. Formally, there exists a valid thinking hierarchy\n\u03c0 such that the ith row of W\u2217 is the \u03c0(i)th row of W, i.e, w\u2217\n\ni = w\u03c0(i).\n\n2.2 Non-negative Congruence Triangularization (NCT)\n\nWith the above model, inferring thinking hierarchy leads to a novel matrix decomposition problem,\nwhich is similar to the symmetric non-negative matrix factorization problem (NMF)6. A non-negative\nmatrix is a matrix whose elements are non-negative.\nDefinition 2.6 (Non-negative Congruence7 Triangularization (NCT)). Given a non-negative matrix\nM, NCT aims to find non-negative matrices W and non-negative upper-triangular matrix \u039b such\nthat M = W\u22a4\u039bW. In a Frobenius norm based approximated version, given a set of matrices W,\nNCT aims to find non-negative matrices W and non-negative upper-triangular matrix \u039b to minimize\n\nmin\nW\u2208W,\u039b\n\n||M \u2212 W\u22a4\u039bW||2\nF\n\nand the minimum is defined as the lack-of-fit of M regarding W 8.\n\nLike NMF, it\u2019s impossible to ask for the strict uniqueness of the results. Let P\u039b be the set of\npermutation matrices such that \u03a0\u22a4\u039b\u03a0 is still upper-triangular.\nIf (W, \u039b) is a solution, then\n(\u03a0\u22121DW, \u03a0\u22a4D\u22121\u039bD\u22121\u03a0) is also a solution where D is a diagonal matrix with positive elements\nand \u03a0 \u2208 P\u039b. We state the uniqueness results as follows and the proof is deferred to Appendix C.\nProposition 2.7 (Uniqueness). If |T | \u2264 |A| and T columns of W consist of a permuted positive\ndiagonal matrix, NCT for M = W\u22a4\u039bW is unique in the sense that then for all W\u2032\u22a4\u039b\u2032W\u2032 =\nW\u22a4\u039bW, there exists a positive diagonal matrix D and a |T | \u00d7 |T | permutation matrix \u03a0 \u2208 P\u039b\nsuch that W\u2032 = \u03a0\u22121DW.\n\nWhen we restrict W to be \u201csemi-orthogonal\u201d, we obtain a clean format of NCT without searching\nfor optimal \u039b. I is the set of all \u201csemi-orthogonal\u201d matrices W where each column of W has\nand only has one non-zero element and WW\u22a4 = I. For example, the W in Example 2.2 can be\nnormalized to a semi-orthogonal matrix. The following lemma follows from the expansion of the\nFrobenius norm and we defer the proof to Appendix C.\n\nLemma 2.8 (Semi-orthogonal: minimizing F-norm = maximizing upper-triangular\u2019s sum of the\nsquare). For all set of matrices W \u2282 I, minW\u2208W,\u039b ||M \u2212 W\u22a4\u039bW||2\nF is equivalent to solv-\ni,j and setting \u039b as Up(WMW\u22a4), the upper-triangular area of\ning maxW\u2208W\nWMW\u22a4.\n\ni\u2264j(WMW\u22a4)2\n\n(cid:80)\n\n2.3\n\nInferring the thinking hierarchy with answer-prediction joint distribution M\n\nGiven M, inferring the thinking hierarchy is equivalent to solving NCT in general. Though we do not\nhave M, later we will show a proxy for M. For simplicity of practical use, we introduce two simple\nranking algorithms by employing Lemma 2.8. The ranking algorithm takes M as input and outputs a\nlinear ordering of answers \u03c0 : {1, 2, \u00b7 \u00b7 \u00b7 , |A|} (cid:55)\u2192 A that maps a ranking position to an answer.\n\nAnswer-Ranking Algorithm (Default) AR(M) The algorithm computes\n\n\u03a0\u2217 \u2190 arg max\n\u03a0\u2208P\n\n(cid:88)\n\n(\u03a0M\u03a0\u22a4)2\ni,j\n\ni\u2264j\n\n6Symmetric NMF: minW ||M \u2212 W\u22a4W||2\nF\n7We use congruence here though it is not matrix congruence since W may not be a square matrix.\n8M = W\u22a4\u039bW, W \u2208 W has zero lack-of-fit.\n\n6\n\n\fwhere P is the set of all |A| \u00d7 |A| permutation matrices. There is a one to one mapping between each\npermutation matrix \u03a0 and a linear ordering \u03c0: \u03a0i,\u03c0(i) = 1, \u2200i. Therefore, the optimal \u03a0\u2217 leads to an\noptimal rank over answers directly and the default algorithm can be also represented as\n\n\u03c0\u2217 \u2190 arg max\n\n\u03c0\n\nM 2\n\n\u03c0(i),\u03c0(j).\n\n(cid:88)\n\ni\u2264j\n\nTo find the optimal rank, we use a dynamic programming based algorithm (see the supplementary\nmaterials) which takes O(2|A||A|2). In practice, |A| is usually at most 7 or 8. In our empirical study,\nthe default algorithm takes 91 milliseconds to finish the computation of all 152 questions.\n\nThe default algorithm implicitly assumes |T | = |A| and all oracles are deterministic. To allow\n|T | < |A| and non-deterministic oracles, we introduce a variant that generalizes P to a subset of\nsemi-orthogonal matrices I. Every |T | \u00d7 |A| semi-orthogonal W indicates a hard clustering. Each\ncluster t \u2208 T contains all answers a such that Wt,a > 0. For example, the W in Example 2.2 can\nbe normalized to a semi-orthogonal matrix and indicates a hard clustering {4}, {6, 3}. Therefore,\nthe variant algorithm will partition the answers into multiple clusters and assign a hierarchy to the\nclusters.\n\nAnswer-Ranking Algorithm (Variant) AR+(M, W) The algorithm computes\n\nW\u2217 \u2190 arg max\nW\u2208I\n\n(cid:88)\n\n(WMW\u22a4)2\n\ni,j.\n\ni\u2264j\n\nwhere W \u2282 I. W\u2217 is normalized such that every row sums to 1. This algorithm does not restrict\n|T | = |A| and learns the optimal |T |.\n\nW\u2217 \u21d2 Answer rank The output W\u2217 indicates a hard clustering of all answers. We rank all answer\nas follows: for any i < j, the answers in cluster i has a higher rank 9 than the answers in cluster j.\nFor all i, for any two answers a, a\u2032 in the same cluster i, a is ranked higher than a\u2032 if W \u2217\ni,a\u2032.\n\ni,a > W \u2217\n\nTheoretical justification When M perfectly fits the model with the restriction that the latent W is\na permutation or a hard clustering, we show that our algorithm finds the thinking hierarchy. Otherwise,\nour algorithm finds the \u201cclosest\u201d solution measured by the Frobenius norm.\nTheorem 2.9. When there exists \u03a00 \u2208 P and non-negative upper-triangular matrix \u039b0 such that\n0 \u039b0\u03a00, AR(M) finds the thinking hierarchy 10. In general, AR(M) will output \u03a0\u2217 where\nM = \u03a0\u22a4\n\u03a0\u2217, \u039b\u2217 = Up(\u03a0\u2217M\u03a0\u2217\u22a4) is a solution to arg min\u03a0\u2208P,\u039b ||M \u2212 \u03a0\u22a4\u039b\u03a0||2\nF . The above statement\nis still valid by replacing P by W \u2282 I and AR(M) by AR+(M, W).\n\nProposition 2.7 and Lemma 2.8 almost directly imply the above theorem. We defer the formal proof\nto Appendix C.\n\n2.4 A proxy for answer-prediction joint distribution M\n\nIn practice, we do not have perfect M. We use the following open-response paradigm to obtain a\nproxy for M.\n\nAnswer-prediction paradigm the respondents are asked Q1: What\u2019s your answer? Answer:\nQ2: What do you think other people will answer:\n\n.\n\nIn the circle example, the possible feedback can be \u201canswer: 4; prediction: 3\u201d, \u201canswer: 3; prediction:\n6,9,1\u201d... We collect all answers provided by the respondents 11 and denote the set of them by A. In\nthe circle example, A = {1, 2, 3, 4, 6, 9}. We also allow respondents to provide no prediction or\nmultiple predictions.\n\n9Rank 1 answer is in the highest position.\n10See definition in the last paragraph in Section 2.1.\n11In practice, we set a threshold \u03b8 and collect answers which are provided by at least \u03b8 fraction of the\nrespondents. We allow multiple predictions and also allow people to answer \u201cI do not know\u201d. See Section 3 for\nmore details.\n\n7\n\n\f(a) Accuracy of algorithms\n\n(b) Empirical distribution of lack-of-fit\n\nFigure 3: The results of our experiment\n\nAnswer-prediction matrix We aggregate the feedback and visualize it by an Answer-Prediction\nmatrix. The Answer-Prediction matrix A is a |A| \u00d7 |A| square matrix where |A| is the number of\ndistinct answers provided by the respondents. Each entry Aa,g, a, g \u2208 A is the number of respondents\nthat answer \u201ca\u201d and predict \u201cg\u201d.\n\nWe will show that with proper assumptions, the answer-prediction matrix A\u2019s expectation is pro-\nportional to M. First, for ease of analysis, we assume that each respondent\u2019s predictions are i.i.d.\nsamples12. Second, since we allow people to optionally provide predictions, we need to additionally\nassume that the number of predictions each respondent is willing to provide is independent of her\ntype and answer. We state the formal result as follows and the proof is deferred to Appendix C.\n\nProposition 2.10. When each respondent\u2019s predictions are i.i.d. samples, and the number of\npredictions she gives is independent of her type and answer, the answer-prediction matrix A\u2019s\nexpectation is proportional to M.\n\n\nBased on this section, do the authors include complete proofs for all their theoretical results?"}]], "q3a": [[{"role": "user", "content": "The following is the experiments section of the paper you are reviewing:\n\n\nWe conduct four studies, study 1 (35 math problems), study 2 (30 Go problems), study 3 (44 general\nknowledge questions), and study 4 (43 Chinese character pronunciation questions).\n\nData collection All studies are performed by online questionnaires. We recruit the respondents by\nan online announcement13 or from an online platform that is similar to Amazon Mechanical Turk. We\nget respondents\u2019 consent for using and sharing their data for research. Respondents are asked not to\nsearch for the answers to the questions or communicate with other people. We allow the respondents\nto answer \u201cI do not know\u201d for all questions. Except for Go problems, all questionnaires use flat\npayment. We illustrate the data collection process in detail in Appendix A. We allow respondents\nto participate in more than one study because our algorithms analyze each question separately and\nindependently.\n\nData processing We merge answers which are the same, like \u20180.5\u2019 and \u201850%\u2019. We omit the answers\nthat are reported by less than (\u2264) 3% of respondents or one person. The remaining answers, excluding\n\u201cI do not know\u201d, form the answer set A whose size is |A|. We then construct the Answer-Prediction\nmatrix and perform our algorithms. Pseudo-codes are attached in Appendix B. Our algorithms do not\nrequire any prior or the respondents\u2019 expertise levels.\n\n3.1 Results\n\n12This may not be a very good assumption since i.i.d. samples can repeat but respondents usually do not\nrepeat their predictions. If we do not want this assumption, we can choose to only use the first prediction from\neach respondent (if there exists) to construct the answer-prediction matrix.\n\n13Many are students from top universities in China. See Appendix A for more details.\n\n8\n\n\fType\nMath\nGo\nGeneral knowledge\nChinese character\n\nTotal Our algorithm(Default) Our algorithm(Variant)\n\n35\n30\n44\n43\n\n29\n28\n41\n36\n\n29\n28\n41\n35\n\nPlurality voting\n24\n23\n35\n34\n\nTable 1: The number of questions our algorithms/baseline are correct.\n\n(a) the Monty Hall problem: you can select one\nclosed door of three. A prize, a car, is behind\none of the doors. The other two doors hide goats.\nAfter you have made your choice, Monty Hall\nwill open one of the remaining doors and show\nthat it does not contain the prize. He then asks\nyou if you would like to switch your choice to\nthe other unopened door. What is the probability\nto get the prize if you switch?\n\n(b) the Taxicab problem: 85% of taxis in this\ncity are green, the others are blue. A witness\nsees a blue taxi. She is usually correct with\nprobability 80%. What is the probability that\nthe taxi saw by the witness is blue?\n\n(c) Pick a move for black such that they can be\nalive.\n\n(d) Pick a move for black such that they can be\nalive by ko.\n\n(e) the boundary question: what river forms the\nboundary between North Korea and China?\n\n(f) the Middle Age New Year question: when\nwas the new year in middle age?\n\n(g) the pronunciation of \u7762\n\n(h) the pronunciation of \u6ec2\n\nFigure 4: The ranked answer-prediction matrices\n\n9\n\n2/31/21/32/31/21/3Answer34261413517146Prediction415080121520415080121520Answer160500008201200801619501104818000522130010218PredictionD3C1B2C2B1D3C1B2C2B1Answer62131091410042012115300002PredictionB8A8B6B7B8A8B6B7Answer112540630001230035PredictionYaluandDoomanYaluSonghuaYaluandDoomanYaluSonghuaAnswer33007410005PredictionApr1Dec25Jan1Apr1Dec25Jan1Answer15410028180633Predictionsui1ju1zhi4zhui1sui1ju1zhi4zhui1Answer115023161300210107Predictionpang1pang2pang1pang2Answer1511216Prediction\fWe compare our approach to the baseline, the plurality voting, regarding the accuracy of the top-\nranking answers. Both of the algorithms beat plurality voting for all studies and the default is slightly\nbetter. Among all 152 questions, in 138 questions, the variant algorithm outputs the same hierarchy as\nthe default algorithm. For other questions, the top-ranking type of the variant algorithm may contain\nmore than one answer. The top-ranking answer is the answer supported by more people among all\nanswers in the top-ranking type. In one question the variant is wrong but the default is correct, the\nvariant algorithm assigns both the correct answer and the incorrect plurality answer to the top-ranking\ntype, thus outputting the incorrect answer as the top-ranking answer.\n\nWe also compute the lack-of-fit index (Definition 2.6) of the algorithms and find that the questions\nthe algorithm outputs the correct answer have a smaller lack-of-fit thus fitting the thinking hierarchy\nmodel better. Therefore, we can use the lack-of-fit index as a reliability index of the algorithms.\n\nWe additionally pick several representative examples for each study (Figure 4) where the matrices\nare ranked by the default algorithm and the diagonal area modified like Example 1.1. In all of these\nexamples, the plurality is incorrect while our approach is correct. Results of other questions are\nillustrated at https://elicitation.info/classroom/1/. Detailed explanations are illustrated\nin Appendix D and here we provide some highlights. First, our approach elicits a rich hierarchy. For\nexample, the taxicab problem is borrowed from Kahneman [8] and previous studies show that people\nusually ignore the base rate and report \u201880%\u2019. The imagined levels can be 41%\u219280%. We elicit a\nmuch richer level \u201c41%\u219250%\u219280%\u219212%\u219215%\u219220%\u201d. Second, the most sophisticated level\nmay fail to predict the least one. In the Taxicab problem, the correct \u201c41%\u201d supporters successfully\npredict the common wrong answer \u201c80%\u201d. However, they fail to predict the surprisingly wrong\nanswers \u201c12%,20%\u201d, which are in contrast successfully predicted by \u201c80%\u201d supporters. Our model\nis sufficiently general to allow this situation. Third, even for problems (like Go) without famous\nmistakes, our approach still works. Moreover, in the boundary question, we identify the correct\nanswer without any prior when only 3 respondents are correct.\n\n\nBased on this section, do the authors include code, data, and instructions needed to reproduce the main experimental results, or provide them in a URL?"}]], "q3b": [[{"role": "user", "content": "The following is the experiments section of the paper you are reviewing:\n\n\nWe conduct four studies, study 1 (35 math problems), study 2 (30 Go problems), study 3 (44 general\nknowledge questions), and study 4 (43 Chinese character pronunciation questions).\n\nData collection All studies are performed by online questionnaires. We recruit the respondents by\nan online announcement13 or from an online platform that is similar to Amazon Mechanical Turk. We\nget respondents\u2019 consent for using and sharing their data for research. Respondents are asked not to\nsearch for the answers to the questions or communicate with other people. We allow the respondents\nto answer \u201cI do not know\u201d for all questions. Except for Go problems, all questionnaires use flat\npayment. We illustrate the data collection process in detail in Appendix A. We allow respondents\nto participate in more than one study because our algorithms analyze each question separately and\nindependently.\n\nData processing We merge answers which are the same, like \u20180.5\u2019 and \u201850%\u2019. We omit the answers\nthat are reported by less than (\u2264) 3% of respondents or one person. The remaining answers, excluding\n\u201cI do not know\u201d, form the answer set A whose size is |A|. We then construct the Answer-Prediction\nmatrix and perform our algorithms. Pseudo-codes are attached in Appendix B. Our algorithms do not\nrequire any prior or the respondents\u2019 expertise levels.\n\n3.1 Results\n\n12This may not be a very good assumption since i.i.d. samples can repeat but respondents usually do not\nrepeat their predictions. If we do not want this assumption, we can choose to only use the first prediction from\neach respondent (if there exists) to construct the answer-prediction matrix.\n\n13Many are students from top universities in China. See Appendix A for more details.\n\n8\n\n\fType\nMath\nGo\nGeneral knowledge\nChinese character\n\nTotal Our algorithm(Default) Our algorithm(Variant)\n\n35\n30\n44\n43\n\n29\n28\n41\n36\n\n29\n28\n41\n35\n\nPlurality voting\n24\n23\n35\n34\n\nTable 1: The number of questions our algorithms/baseline are correct.\n\n(a) the Monty Hall problem: you can select one\nclosed door of three. A prize, a car, is behind\none of the doors. The other two doors hide goats.\nAfter you have made your choice, Monty Hall\nwill open one of the remaining doors and show\nthat it does not contain the prize. He then asks\nyou if you would like to switch your choice to\nthe other unopened door. What is the probability\nto get the prize if you switch?\n\n(b) the Taxicab problem: 85% of taxis in this\ncity are green, the others are blue. A witness\nsees a blue taxi. She is usually correct with\nprobability 80%. What is the probability that\nthe taxi saw by the witness is blue?\n\n(c) Pick a move for black such that they can be\nalive.\n\n(d) Pick a move for black such that they can be\nalive by ko.\n\n(e) the boundary question: what river forms the\nboundary between North Korea and China?\n\n(f) the Middle Age New Year question: when\nwas the new year in middle age?\n\n(g) the pronunciation of \u7762\n\n(h) the pronunciation of \u6ec2\n\nFigure 4: The ranked answer-prediction matrices\n\n9\n\n2/31/21/32/31/21/3Answer34261413517146Prediction415080121520415080121520Answer160500008201200801619501104818000522130010218PredictionD3C1B2C2B1D3C1B2C2B1Answer62131091410042012115300002PredictionB8A8B6B7B8A8B6B7Answer112540630001230035PredictionYaluandDoomanYaluSonghuaYaluandDoomanYaluSonghuaAnswer33007410005PredictionApr1Dec25Jan1Apr1Dec25Jan1Answer15410028180633Predictionsui1ju1zhi4zhui1sui1ju1zhi4zhui1Answer115023161300210107Predictionpang1pang2pang1pang2Answer1511216Prediction\fWe compare our approach to the baseline, the plurality voting, regarding the accuracy of the top-\nranking answers. Both of the algorithms beat plurality voting for all studies and the default is slightly\nbetter. Among all 152 questions, in 138 questions, the variant algorithm outputs the same hierarchy as\nthe default algorithm. For other questions, the top-ranking type of the variant algorithm may contain\nmore than one answer. The top-ranking answer is the answer supported by more people among all\nanswers in the top-ranking type. In one question the variant is wrong but the default is correct, the\nvariant algorithm assigns both the correct answer and the incorrect plurality answer to the top-ranking\ntype, thus outputting the incorrect answer as the top-ranking answer.\n\nWe also compute the lack-of-fit index (Definition 2.6) of the algorithms and find that the questions\nthe algorithm outputs the correct answer have a smaller lack-of-fit thus fitting the thinking hierarchy\nmodel better. Therefore, we can use the lack-of-fit index as a reliability index of the algorithms.\n\nWe additionally pick several representative examples for each study (Figure 4) where the matrices\nare ranked by the default algorithm and the diagonal area modified like Example 1.1. In all of these\nexamples, the plurality is incorrect while our approach is correct. Results of other questions are\nillustrated at https://elicitation.info/classroom/1/. Detailed explanations are illustrated\nin Appendix D and here we provide some highlights. First, our approach elicits a rich hierarchy. For\nexample, the taxicab problem is borrowed from Kahneman [8] and previous studies show that people\nusually ignore the base rate and report \u201880%\u2019. The imagined levels can be 41%\u219280%. We elicit a\nmuch richer level \u201c41%\u219250%\u219280%\u219212%\u219215%\u219220%\u201d. Second, the most sophisticated level\nmay fail to predict the least one. In the Taxicab problem, the correct \u201c41%\u201d supporters successfully\npredict the common wrong answer \u201c80%\u201d. However, they fail to predict the surprisingly wrong\nanswers \u201c12%,20%\u201d, which are in contrast successfully predicted by \u201c80%\u201d supporters. Our model\nis sufficiently general to allow this situation. Third, even for problems (like Go) without famous\nmistakes, our approach still works. Moreover, in the boundary question, we identify the correct\nanswer without any prior when only 3 respondents are correct.\n\nBased on this section, do the authors specify all training details (e.g., data splits, hyperparameters, how they were chosen) for their results?"}]], "q3c": [[{"role": "user", "content": "The following is the experiments section of the paper you are reviewing:\n\n\nWe conduct four studies, study 1 (35 math problems), study 2 (30 Go problems), study 3 (44 general\nknowledge questions), and study 4 (43 Chinese character pronunciation questions).\n\nData collection All studies are performed by online questionnaires. We recruit the respondents by\nan online announcement13 or from an online platform that is similar to Amazon Mechanical Turk. We\nget respondents\u2019 consent for using and sharing their data for research. Respondents are asked not to\nsearch for the answers to the questions or communicate with other people. We allow the respondents\nto answer \u201cI do not know\u201d for all questions. Except for Go problems, all questionnaires use flat\npayment. We illustrate the data collection process in detail in Appendix A. We allow respondents\nto participate in more than one study because our algorithms analyze each question separately and\nindependently.\n\nData processing We merge answers which are the same, like \u20180.5\u2019 and \u201850%\u2019. We omit the answers\nthat are reported by less than (\u2264) 3% of respondents or one person. The remaining answers, excluding\n\u201cI do not know\u201d, form the answer set A whose size is |A|. We then construct the Answer-Prediction\nmatrix and perform our algorithms. Pseudo-codes are attached in Appendix B. Our algorithms do not\nrequire any prior or the respondents\u2019 expertise levels.\n\n3.1 Results\n\n12This may not be a very good assumption since i.i.d. samples can repeat but respondents usually do not\nrepeat their predictions. If we do not want this assumption, we can choose to only use the first prediction from\neach respondent (if there exists) to construct the answer-prediction matrix.\n\n13Many are students from top universities in China. See Appendix A for more details.\n\n8\n\n\fType\nMath\nGo\nGeneral knowledge\nChinese character\n\nTotal Our algorithm(Default) Our algorithm(Variant)\n\n35\n30\n44\n43\n\n29\n28\n41\n36\n\n29\n28\n41\n35\n\nPlurality voting\n24\n23\n35\n34\n\nTable 1: The number of questions our algorithms/baseline are correct.\n\n(a) the Monty Hall problem: you can select one\nclosed door of three. A prize, a car, is behind\none of the doors. The other two doors hide goats.\nAfter you have made your choice, Monty Hall\nwill open one of the remaining doors and show\nthat it does not contain the prize. He then asks\nyou if you would like to switch your choice to\nthe other unopened door. What is the probability\nto get the prize if you switch?\n\n(b) the Taxicab problem: 85% of taxis in this\ncity are green, the others are blue. A witness\nsees a blue taxi. She is usually correct with\nprobability 80%. What is the probability that\nthe taxi saw by the witness is blue?\n\n(c) Pick a move for black such that they can be\nalive.\n\n(d) Pick a move for black such that they can be\nalive by ko.\n\n(e) the boundary question: what river forms the\nboundary between North Korea and China?\n\n(f) the Middle Age New Year question: when\nwas the new year in middle age?\n\n(g) the pronunciation of \u7762\n\n(h) the pronunciation of \u6ec2\n\nFigure 4: The ranked answer-prediction matrices\n\n9\n\n2/31/21/32/31/21/3Answer34261413517146Prediction415080121520415080121520Answer160500008201200801619501104818000522130010218PredictionD3C1B2C2B1D3C1B2C2B1Answer62131091410042012115300002PredictionB8A8B6B7B8A8B6B7Answer112540630001230035PredictionYaluandDoomanYaluSonghuaYaluandDoomanYaluSonghuaAnswer33007410005PredictionApr1Dec25Jan1Apr1Dec25Jan1Answer15410028180633Predictionsui1ju1zhi4zhui1sui1ju1zhi4zhui1Answer115023161300210107Predictionpang1pang2pang1pang2Answer1511216Prediction\fWe compare our approach to the baseline, the plurality voting, regarding the accuracy of the top-\nranking answers. Both of the algorithms beat plurality voting for all studies and the default is slightly\nbetter. Among all 152 questions, in 138 questions, the variant algorithm outputs the same hierarchy as\nthe default algorithm. For other questions, the top-ranking type of the variant algorithm may contain\nmore than one answer. The top-ranking answer is the answer supported by more people among all\nanswers in the top-ranking type. In one question the variant is wrong but the default is correct, the\nvariant algorithm assigns both the correct answer and the incorrect plurality answer to the top-ranking\ntype, thus outputting the incorrect answer as the top-ranking answer.\n\nWe also compute the lack-of-fit index (Definition 2.6) of the algorithms and find that the questions\nthe algorithm outputs the correct answer have a smaller lack-of-fit thus fitting the thinking hierarchy\nmodel better. Therefore, we can use the lack-of-fit index as a reliability index of the algorithms.\n\nWe additionally pick several representative examples for each study (Figure 4) where the matrices\nare ranked by the default algorithm and the diagonal area modified like Example 1.1. In all of these\nexamples, the plurality is incorrect while our approach is correct. Results of other questions are\nillustrated at https://elicitation.info/classroom/1/. Detailed explanations are illustrated\nin Appendix D and here we provide some highlights. First, our approach elicits a rich hierarchy. For\nexample, the taxicab problem is borrowed from Kahneman [8] and previous studies show that people\nusually ignore the base rate and report \u201880%\u2019. The imagined levels can be 41%\u219280%. We elicit a\nmuch richer level \u201c41%\u219250%\u219280%\u219212%\u219215%\u219220%\u201d. Second, the most sophisticated level\nmay fail to predict the least one. In the Taxicab problem, the correct \u201c41%\u201d supporters successfully\npredict the common wrong answer \u201c80%\u201d. However, they fail to predict the surprisingly wrong\nanswers \u201c12%,20%\u201d, which are in contrast successfully predicted by \u201c80%\u201d supporters. Our model\nis sufficiently general to allow this situation. Third, even for problems (like Go) without famous\nmistakes, our approach still works. Moreover, in the boundary question, we identify the correct\nanswer without any prior when only 3 respondents are correct.\n\nBased on this section, do the authors report error bars (e.g., with respect to the random seed after running experiments multiple times)?"}]], "q3d": [[{"role": "user", "content": "The following is the experiments section of the paper you are reviewing:\n\n\nWe conduct four studies, study 1 (35 math problems), study 2 (30 Go problems), study 3 (44 general\nknowledge questions), and study 4 (43 Chinese character pronunciation questions).\n\nData collection All studies are performed by online questionnaires. We recruit the respondents by\nan online announcement13 or from an online platform that is similar to Amazon Mechanical Turk. We\nget respondents\u2019 consent for using and sharing their data for research. Respondents are asked not to\nsearch for the answers to the questions or communicate with other people. We allow the respondents\nto answer \u201cI do not know\u201d for all questions. Except for Go problems, all questionnaires use flat\npayment. We illustrate the data collection process in detail in Appendix A. We allow respondents\nto participate in more than one study because our algorithms analyze each question separately and\nindependently.\n\nData processing We merge answers which are the same, like \u20180.5\u2019 and \u201850%\u2019. We omit the answers\nthat are reported by less than (\u2264) 3% of respondents or one person. The remaining answers, excluding\n\u201cI do not know\u201d, form the answer set A whose size is |A|. We then construct the Answer-Prediction\nmatrix and perform our algorithms. Pseudo-codes are attached in Appendix B. Our algorithms do not\nrequire any prior or the respondents\u2019 expertise levels.\n\n3.1 Results\n\n12This may not be a very good assumption since i.i.d. samples can repeat but respondents usually do not\nrepeat their predictions. If we do not want this assumption, we can choose to only use the first prediction from\neach respondent (if there exists) to construct the answer-prediction matrix.\n\n13Many are students from top universities in China. See Appendix A for more details.\n\n8\n\n\fType\nMath\nGo\nGeneral knowledge\nChinese character\n\nTotal Our algorithm(Default) Our algorithm(Variant)\n\n35\n30\n44\n43\n\n29\n28\n41\n36\n\n29\n28\n41\n35\n\nPlurality voting\n24\n23\n35\n34\n\nTable 1: The number of questions our algorithms/baseline are correct.\n\n(a) the Monty Hall problem: you can select one\nclosed door of three. A prize, a car, is behind\none of the doors. The other two doors hide goats.\nAfter you have made your choice, Monty Hall\nwill open one of the remaining doors and show\nthat it does not contain the prize. He then asks\nyou if you would like to switch your choice to\nthe other unopened door. What is the probability\nto get the prize if you switch?\n\n(b) the Taxicab problem: 85% of taxis in this\ncity are green, the others are blue. A witness\nsees a blue taxi. She is usually correct with\nprobability 80%. What is the probability that\nthe taxi saw by the witness is blue?\n\n(c) Pick a move for black such that they can be\nalive.\n\n(d) Pick a move for black such that they can be\nalive by ko.\n\n(e) the boundary question: what river forms the\nboundary between North Korea and China?\n\n(f) the Middle Age New Year question: when\nwas the new year in middle age?\n\n(g) the pronunciation of \u7762\n\n(h) the pronunciation of \u6ec2\n\nFigure 4: The ranked answer-prediction matrices\n\n9\n\n2/31/21/32/31/21/3Answer34261413517146Prediction415080121520415080121520Answer160500008201200801619501104818000522130010218PredictionD3C1B2C2B1D3C1B2C2B1Answer62131091410042012115300002PredictionB8A8B6B7B8A8B6B7Answer112540630001230035PredictionYaluandDoomanYaluSonghuaYaluandDoomanYaluSonghuaAnswer33007410005PredictionApr1Dec25Jan1Apr1Dec25Jan1Answer15410028180633Predictionsui1ju1zhi4zhui1sui1ju1zhi4zhui1Answer115023161300210107Predictionpang1pang2pang1pang2Answer1511216Prediction\fWe compare our approach to the baseline, the plurality voting, regarding the accuracy of the top-\nranking answers. Both of the algorithms beat plurality voting for all studies and the default is slightly\nbetter. Among all 152 questions, in 138 questions, the variant algorithm outputs the same hierarchy as\nthe default algorithm. For other questions, the top-ranking type of the variant algorithm may contain\nmore than one answer. The top-ranking answer is the answer supported by more people among all\nanswers in the top-ranking type. In one question the variant is wrong but the default is correct, the\nvariant algorithm assigns both the correct answer and the incorrect plurality answer to the top-ranking\ntype, thus outputting the incorrect answer as the top-ranking answer.\n\nWe also compute the lack-of-fit index (Definition 2.6) of the algorithms and find that the questions\nthe algorithm outputs the correct answer have a smaller lack-of-fit thus fitting the thinking hierarchy\nmodel better. Therefore, we can use the lack-of-fit index as a reliability index of the algorithms.\n\nWe additionally pick several representative examples for each study (Figure 4) where the matrices\nare ranked by the default algorithm and the diagonal area modified like Example 1.1. In all of these\nexamples, the plurality is incorrect while our approach is correct. Results of other questions are\nillustrated at https://elicitation.info/classroom/1/. Detailed explanations are illustrated\nin Appendix D and here we provide some highlights. First, our approach elicits a rich hierarchy. For\nexample, the taxicab problem is borrowed from Kahneman [8] and previous studies show that people\nusually ignore the base rate and report \u201880%\u2019. The imagined levels can be 41%\u219280%. We elicit a\nmuch richer level \u201c41%\u219250%\u219280%\u219212%\u219215%\u219220%\u201d. Second, the most sophisticated level\nmay fail to predict the least one. In the Taxicab problem, the correct \u201c41%\u201d supporters successfully\npredict the common wrong answer \u201c80%\u201d. However, they fail to predict the surprisingly wrong\nanswers \u201c12%,20%\u201d, which are in contrast successfully predicted by \u201c80%\u201d supporters. Our model\nis sufficiently general to allow this situation. Third, even for problems (like Go) without famous\nmistakes, our approach still works. Moreover, in the boundary question, we identify the correct\nanswer without any prior when only 3 respondents are correct.\n\nBased on this section, do the authors include the amount of compute and type of resources used (e.g., type of GPUs, internal cluster, or cloud provider)?"}]], "q4a": [[{"role": "user", "content": "The following is the methods section of the paper you are reviewing:\n\n\nWe first introduce our model for thinking hierarchy. Tversky and Kahneman [27] propose that people\nhave two systems, a fast and intuitive system, and a slow and logical system. For example, Alice\nstarts to solve the circle problem. When she reads the question, she can run her intuitive system 1 and\nobtain answer \u201c3\u201d. However, when she starts to think carefully, she runs her more careful system 2 to\nobtain answer \u201c4\u201d.\n\nWe propose a more general model where people can run multiple oracles to approach the question\nduring their thinking process. Conceptually similar to the cognitive hierarchy theory [3], we assume\nthe oracles have different levels. People usually run lower level oracles before the higher level oracles.\nIn the previous example, system 1 is the lower level oracle and system 2 is the higher one. We assume\nthat Alice runs system 2 after system 1. Thus, in our model, people who know the answer is \u201c4\u201d can\n\n4\n\n\fpredict that other people answer \u201c3\u201d, which is hypothesized in Kong and Schoenebeck [10]. It\u2019s also\npossible that some people run the most sophisticated oracle directly without running the lower ones.\nThus, we design the model such that it does not require the higher-type to be able to predict ALL\nlower types. We also allow the oracles\u2019 outputs to be random.\n\nSection 2.1 introduces the model of thinking hierarchy. Section 2.2 reduces the model inference\nproblem to a matrix decomposition problem. Section 2.3 and section 2.4 show how to learn the\nthinking hierarchy.\n\n2.1 Thinking hierarchy\n\nFixing a question q (e.g. the circle problem), T denotes the set of thinking types. A denotes the set of\npossible answers. Both T and A are finite sets. \u2206A denotes all possible distributions over A. We\nsometimes use \u201cprob\u201d as a shorthand for probability.\n\nGenerating answers We will describe how people of different thinking types generate answers.\nDefinition 2.1 (Oracles of thinking types W ). An answer generating oracle maps the question to\nan (random) answer in A. Each type t corresponds to an oracle Ot. The output Ot(q) is a random\nvariable whose distribution is wt \u2208 \u2206A. W denotes a |T | \u00d7 |A| matrix where each row t is wt.\nEach respondent is type t with prob pt and (cid:80)\nrunning the oracle Ot. For all a \u2208 A, the probability that a respondent answers a will be (cid:80)\nWe assume the probability is positive for all a \u2208 A.\nExample 2.2 (A running example). There are two types T = {0, 1}. The answer space is A =\n{3, 4, 6}. O0 will output \u20183\u2019 with probability 0.8 and \u20186\u2019 with probability 0.2. O1 will output \u20184\u2019\n0\n1\n\nt pt = 1. A type t respondent generates the answer by\nt ptwt(a).\n\ndeterministically. In this example, W =\n\nwhere the first row is the distribution of\n\n(cid:20)0.8\n0\n\n0.2\n0\n\n(cid:21)\n\nO0\u2019s output and the second row is the distribution of O1\u2019s output.\n\nGenerating predictions We then describe how people of different thinking types predict what other\npeople will answer. Here the prediction is not a distribution, but an answer other people may report.\nWhen a type t respondent makes a prediction, she will run an oracle, which is Ot\u2032 with probability\npt\u2192t\u2032 where (cid:80)\n\nt\u2032 pt\u2192t\u2032 = 1. She uses the output of Ot\u2032 as the prediction g \u2208 A.\n\nCombination: answer-prediction joint distribution M M denotes a |A| \u00d7 |A| matrix where\nMa,g is the probability an respondent answers a and predicts g. \u039b denotes a |T | \u00d7 |T | matrix where\n\u039bt,t\u2032 = ptpt\u2192t\u2032 is the probability a respondent is type t and predicts type t\u2032.\nExample 2.3. In this example, when type 0 respondent makes a prediction, with prob 1, she will run\nO0 again. When type 1 respondent makes a prediction, with prob 0.5, she will run O1 again, with\nprob 0.5, she will run O0. Moreover, a respondent is type 0 with prob 0.7, and type 1 with prob 0.3.\n\nHere \u039b =\n\n(cid:20)p0p0\u21920\np1p1\u21920\n\np0p0\u21921\np1p1\u21921\n\n(cid:21)\n\n=\n\n(cid:20) 0.7 \u2217 1\n0.3 \u2217 0.5\n\n0.7 \u2217 0\n0.3 \u2217 0.5\n\n(cid:21)\n\n=\n\n(cid:20) 0.7\n0.15\n\n(cid:21)\n\n.\n\n0\n0.15\n\nClaim 2.4. Based on the above generating processes, M = W\u22a4\u039bW.\n\nProof. For each respondent, the probability she answers a and predicts g will be\n(cid:88)\n\n(cid:88)\n\n(cid:88)\n\nptwt(a)\n\npt\u2192t\u2032wt\u2032(g) =\n\nwt(a)ptpt\u2192t\u2032wt\u2032(g).\n\nMa,g =\n\nt\n\nt\u2032\n\nt,t\u2032\n\nWe sum over all possible types the respondent will be. Given she is type t, she runs oracle Ot to\ngenerate the answer and wt(a) is the probability that the answer is a. We sum over all possible\noracles she runs to predict. Given that she runs Ot\u2032, wt\u2032(g) is the probability the prediction is g.\n\nKey assumption: upper-triangular \u039b we assume that people of a less sophisticated level can\nnever run the oracles of more sophisticated levels. A linear ordering of types \u03c0 : {1, 2, \u00b7 \u00b7 \u00b7 , |T |} (cid:55)\u2192 T\nmaps a ranking position to a type. For example, \u03c0(1) \u2208 T is the top-ranking type.\nAssumption 2.5. We assume that with a proper ordering \u03c0 of the types, \u039b is an upper-triangular\nmatrix. Formally, there exists \u03c0 such that \u2200i > j, \u039b\u03c0(i),\u03c0(j) = 0. Any \u03c0 that makes \u039b upper-\ntriangular is a valid thinking hierarchy of the types.\n\n5\n\n\fIn the running example, the valid thinking hierarchy is \u03c0(1) = type 1, \u03c0(2) = type 0. Note that the\nabove assumption does not require \u2200i \u2264 j, \u039b\u03c0(i),\u03c0(j) > 0. When \u039b is a diagonal matrix, types cannot\npredict each other and are equally sophisticated, thus any ordering is a valid thinking hierarchy.\n\nAn algorithm finds the thinking hierarchy when the algorithm is given M which is generated by\nlatent (unknown) W, \u039b, and the algorithm will output a matrix W\u2217 which equals a row-permuted\nW where the row order is a valid thinking hierarchy. Formally, there exists a valid thinking hierarchy\n\u03c0 such that the ith row of W\u2217 is the \u03c0(i)th row of W, i.e, w\u2217\n\ni = w\u03c0(i).\n\n2.2 Non-negative Congruence Triangularization (NCT)\n\nWith the above model, inferring thinking hierarchy leads to a novel matrix decomposition problem,\nwhich is similar to the symmetric non-negative matrix factorization problem (NMF)6. A non-negative\nmatrix is a matrix whose elements are non-negative.\nDefinition 2.6 (Non-negative Congruence7 Triangularization (NCT)). Given a non-negative matrix\nM, NCT aims to find non-negative matrices W and non-negative upper-triangular matrix \u039b such\nthat M = W\u22a4\u039bW. In a Frobenius norm based approximated version, given a set of matrices W,\nNCT aims to find non-negative matrices W and non-negative upper-triangular matrix \u039b to minimize\n\nmin\nW\u2208W,\u039b\n\n||M \u2212 W\u22a4\u039bW||2\nF\n\nand the minimum is defined as the lack-of-fit of M regarding W 8.\n\nLike NMF, it\u2019s impossible to ask for the strict uniqueness of the results. Let P\u039b be the set of\npermutation matrices such that \u03a0\u22a4\u039b\u03a0 is still upper-triangular.\nIf (W, \u039b) is a solution, then\n(\u03a0\u22121DW, \u03a0\u22a4D\u22121\u039bD\u22121\u03a0) is also a solution where D is a diagonal matrix with positive elements\nand \u03a0 \u2208 P\u039b. We state the uniqueness results as follows and the proof is deferred to Appendix C.\nProposition 2.7 (Uniqueness). If |T | \u2264 |A| and T columns of W consist of a permuted positive\ndiagonal matrix, NCT for M = W\u22a4\u039bW is unique in the sense that then for all W\u2032\u22a4\u039b\u2032W\u2032 =\nW\u22a4\u039bW, there exists a positive diagonal matrix D and a |T | \u00d7 |T | permutation matrix \u03a0 \u2208 P\u039b\nsuch that W\u2032 = \u03a0\u22121DW.\n\nWhen we restrict W to be \u201csemi-orthogonal\u201d, we obtain a clean format of NCT without searching\nfor optimal \u039b. I is the set of all \u201csemi-orthogonal\u201d matrices W where each column of W has\nand only has one non-zero element and WW\u22a4 = I. For example, the W in Example 2.2 can be\nnormalized to a semi-orthogonal matrix. The following lemma follows from the expansion of the\nFrobenius norm and we defer the proof to Appendix C.\n\nLemma 2.8 (Semi-orthogonal: minimizing F-norm = maximizing upper-triangular\u2019s sum of the\nsquare). For all set of matrices W \u2282 I, minW\u2208W,\u039b ||M \u2212 W\u22a4\u039bW||2\nF is equivalent to solv-\ni,j and setting \u039b as Up(WMW\u22a4), the upper-triangular area of\ning maxW\u2208W\nWMW\u22a4.\n\ni\u2264j(WMW\u22a4)2\n\n(cid:80)\n\n2.3\n\nInferring the thinking hierarchy with answer-prediction joint distribution M\n\nGiven M, inferring the thinking hierarchy is equivalent to solving NCT in general. Though we do not\nhave M, later we will show a proxy for M. For simplicity of practical use, we introduce two simple\nranking algorithms by employing Lemma 2.8. The ranking algorithm takes M as input and outputs a\nlinear ordering of answers \u03c0 : {1, 2, \u00b7 \u00b7 \u00b7 , |A|} (cid:55)\u2192 A that maps a ranking position to an answer.\n\nAnswer-Ranking Algorithm (Default) AR(M) The algorithm computes\n\n\u03a0\u2217 \u2190 arg max\n\u03a0\u2208P\n\n(cid:88)\n\n(\u03a0M\u03a0\u22a4)2\ni,j\n\ni\u2264j\n\n6Symmetric NMF: minW ||M \u2212 W\u22a4W||2\nF\n7We use congruence here though it is not matrix congruence since W may not be a square matrix.\n8M = W\u22a4\u039bW, W \u2208 W has zero lack-of-fit.\n\n6\n\n\fwhere P is the set of all |A| \u00d7 |A| permutation matrices. There is a one to one mapping between each\npermutation matrix \u03a0 and a linear ordering \u03c0: \u03a0i,\u03c0(i) = 1, \u2200i. Therefore, the optimal \u03a0\u2217 leads to an\noptimal rank over answers directly and the default algorithm can be also represented as\n\n\u03c0\u2217 \u2190 arg max\n\n\u03c0\n\nM 2\n\n\u03c0(i),\u03c0(j).\n\n(cid:88)\n\ni\u2264j\n\nTo find the optimal rank, we use a dynamic programming based algorithm (see the supplementary\nmaterials) which takes O(2|A||A|2). In practice, |A| is usually at most 7 or 8. In our empirical study,\nthe default algorithm takes 91 milliseconds to finish the computation of all 152 questions.\n\nThe default algorithm implicitly assumes |T | = |A| and all oracles are deterministic. To allow\n|T | < |A| and non-deterministic oracles, we introduce a variant that generalizes P to a subset of\nsemi-orthogonal matrices I. Every |T | \u00d7 |A| semi-orthogonal W indicates a hard clustering. Each\ncluster t \u2208 T contains all answers a such that Wt,a > 0. For example, the W in Example 2.2 can\nbe normalized to a semi-orthogonal matrix and indicates a hard clustering {4}, {6, 3}. Therefore,\nthe variant algorithm will partition the answers into multiple clusters and assign a hierarchy to the\nclusters.\n\nAnswer-Ranking Algorithm (Variant) AR+(M, W) The algorithm computes\n\nW\u2217 \u2190 arg max\nW\u2208I\n\n(cid:88)\n\n(WMW\u22a4)2\n\ni,j.\n\ni\u2264j\n\nwhere W \u2282 I. W\u2217 is normalized such that every row sums to 1. This algorithm does not restrict\n|T | = |A| and learns the optimal |T |.\n\nW\u2217 \u21d2 Answer rank The output W\u2217 indicates a hard clustering of all answers. We rank all answer\nas follows: for any i < j, the answers in cluster i has a higher rank 9 than the answers in cluster j.\nFor all i, for any two answers a, a\u2032 in the same cluster i, a is ranked higher than a\u2032 if W \u2217\ni,a\u2032.\n\ni,a > W \u2217\n\nTheoretical justification When M perfectly fits the model with the restriction that the latent W is\na permutation or a hard clustering, we show that our algorithm finds the thinking hierarchy. Otherwise,\nour algorithm finds the \u201cclosest\u201d solution measured by the Frobenius norm.\nTheorem 2.9. When there exists \u03a00 \u2208 P and non-negative upper-triangular matrix \u039b0 such that\n0 \u039b0\u03a00, AR(M) finds the thinking hierarchy 10. In general, AR(M) will output \u03a0\u2217 where\nM = \u03a0\u22a4\n\u03a0\u2217, \u039b\u2217 = Up(\u03a0\u2217M\u03a0\u2217\u22a4) is a solution to arg min\u03a0\u2208P,\u039b ||M \u2212 \u03a0\u22a4\u039b\u03a0||2\nF . The above statement\nis still valid by replacing P by W \u2282 I and AR(M) by AR+(M, W).\n\nProposition 2.7 and Lemma 2.8 almost directly imply the above theorem. We defer the formal proof\nto Appendix C.\n\n2.4 A proxy for answer-prediction joint distribution M\n\nIn practice, we do not have perfect M. We use the following open-response paradigm to obtain a\nproxy for M.\n\nAnswer-prediction paradigm the respondents are asked Q1: What\u2019s your answer? Answer:\nQ2: What do you think other people will answer:\n\n.\n\nIn the circle example, the possible feedback can be \u201canswer: 4; prediction: 3\u201d, \u201canswer: 3; prediction:\n6,9,1\u201d... We collect all answers provided by the respondents 11 and denote the set of them by A. In\nthe circle example, A = {1, 2, 3, 4, 6, 9}. We also allow respondents to provide no prediction or\nmultiple predictions.\n\n9Rank 1 answer is in the highest position.\n10See definition in the last paragraph in Section 2.1.\n11In practice, we set a threshold \u03b8 and collect answers which are provided by at least \u03b8 fraction of the\nrespondents. We allow multiple predictions and also allow people to answer \u201cI do not know\u201d. See Section 3 for\nmore details.\n\n7\n\n\f(a) Accuracy of algorithms\n\n(b) Empirical distribution of lack-of-fit\n\nFigure 3: The results of our experiment\n\nAnswer-prediction matrix We aggregate the feedback and visualize it by an Answer-Prediction\nmatrix. The Answer-Prediction matrix A is a |A| \u00d7 |A| square matrix where |A| is the number of\ndistinct answers provided by the respondents. Each entry Aa,g, a, g \u2208 A is the number of respondents\nthat answer \u201ca\u201d and predict \u201cg\u201d.\n\nWe will show that with proper assumptions, the answer-prediction matrix A\u2019s expectation is pro-\nportional to M. First, for ease of analysis, we assume that each respondent\u2019s predictions are i.i.d.\nsamples12. Second, since we allow people to optionally provide predictions, we need to additionally\nassume that the number of predictions each respondent is willing to provide is independent of her\ntype and answer. We state the formal result as follows and the proof is deferred to Appendix C.\n\nProposition 2.10. When each respondent\u2019s predictions are i.i.d. samples, and the number of\npredictions she gives is independent of her type and answer, the answer-prediction matrix A\u2019s\nexpectation is proportional to M.\n\n\nBased on this section, do the authors use existing assets (e.g., code, data, models) that are not new contributions in their paper? Please start your answer with \"Yes\", \"No\", or \"Unsure\"."}, {"role": "user", "content": "The following is the experiments section of the paper you are reviewing:\nexperiments section: \n\nWe conduct four studies, study 1 (35 math problems), study 2 (30 Go problems), study 3 (44 general\nknowledge questions), and study 4 (43 Chinese character pronunciation questions).\n\nData collection All studies are performed by online questionnaires. We recruit the respondents by\nan online announcement13 or from an online platform that is similar to Amazon Mechanical Turk. We\nget respondents\u2019 consent for using and sharing their data for research. Respondents are asked not to\nsearch for the answers to the questions or communicate with other people. We allow the respondents\nto answer \u201cI do not know\u201d for all questions. Except for Go problems, all questionnaires use flat\npayment. We illustrate the data collection process in detail in Appendix A. We allow respondents\nto participate in more than one study because our algorithms analyze each question separately and\nindependently.\n\nData processing We merge answers which are the same, like \u20180.5\u2019 and \u201850%\u2019. We omit the answers\nthat are reported by less than (\u2264) 3% of respondents or one person. The remaining answers, excluding\n\u201cI do not know\u201d, form the answer set A whose size is |A|. We then construct the Answer-Prediction\nmatrix and perform our algorithms. Pseudo-codes are attached in Appendix B. Our algorithms do not\nrequire any prior or the respondents\u2019 expertise levels.\n\n3.1 Results\n\n12This may not be a very good assumption since i.i.d. samples can repeat but respondents usually do not\nrepeat their predictions. If we do not want this assumption, we can choose to only use the first prediction from\neach respondent (if there exists) to construct the answer-prediction matrix.\n\n13Many are students from top universities in China. See Appendix A for more details.\n\n8\n\n\fType\nMath\nGo\nGeneral knowledge\nChinese character\n\nTotal Our algorithm(Default) Our algorithm(Variant)\n\n35\n30\n44\n43\n\n29\n28\n41\n36\n\n29\n28\n41\n35\n\nPlurality voting\n24\n23\n35\n34\n\nTable 1: The number of questions our algorithms/baseline are correct.\n\n(a) the Monty Hall problem: you can select one\nclosed door of three. A prize, a car, is behind\none of the doors. The other two doors hide goats.\nAfter you have made your choice, Monty Hall\nwill open one of the remaining doors and show\nthat it does not contain the prize. He then asks\nyou if you would like to switch your choice to\nthe other unopened door. What is the probability\nto get the prize if you switch?\n\n(b) the Taxicab problem: 85% of taxis in this\ncity are green, the others are blue. A witness\nsees a blue taxi. She is usually correct with\nprobability 80%. What is the probability that\nthe taxi saw by the witness is blue?\n\n(c) Pick a move for black such that they can be\nalive.\n\n(d) Pick a move for black such that they can be\nalive by ko.\n\n(e) the boundary question: what river forms the\nboundary between North Korea and China?\n\n(f) the Middle Age New Year question: when\nwas the new year in middle age?\n\n(g) the pronunciation of \u7762\n\n(h) the pronunciation of \u6ec2\n\nFigure 4: The ranked answer-prediction matrices\n\n9\n\n2/31/21/32/31/21/3Answer34261413517146Prediction415080121520415080121520Answer160500008201200801619501104818000522130010218PredictionD3C1B2C2B1D3C1B2C2B1Answer62131091410042012115300002PredictionB8A8B6B7B8A8B6B7Answer112540630001230035PredictionYaluandDoomanYaluSonghuaYaluandDoomanYaluSonghuaAnswer33007410005PredictionApr1Dec25Jan1Apr1Dec25Jan1Answer15410028180633Predictionsui1ju1zhi4zhui1sui1ju1zhi4zhui1Answer115023161300210107Predictionpang1pang2pang1pang2Answer1511216Prediction\fWe compare our approach to the baseline, the plurality voting, regarding the accuracy of the top-\nranking answers. Both of the algorithms beat plurality voting for all studies and the default is slightly\nbetter. Among all 152 questions, in 138 questions, the variant algorithm outputs the same hierarchy as\nthe default algorithm. For other questions, the top-ranking type of the variant algorithm may contain\nmore than one answer. The top-ranking answer is the answer supported by more people among all\nanswers in the top-ranking type. In one question the variant is wrong but the default is correct, the\nvariant algorithm assigns both the correct answer and the incorrect plurality answer to the top-ranking\ntype, thus outputting the incorrect answer as the top-ranking answer.\n\nWe also compute the lack-of-fit index (Definition 2.6) of the algorithms and find that the questions\nthe algorithm outputs the correct answer have a smaller lack-of-fit thus fitting the thinking hierarchy\nmodel better. Therefore, we can use the lack-of-fit index as a reliability index of the algorithms.\n\nWe additionally pick several representative examples for each study (Figure 4) where the matrices\nare ranked by the default algorithm and the diagonal area modified like Example 1.1. In all of these\nexamples, the plurality is incorrect while our approach is correct. Results of other questions are\nillustrated at https://elicitation.info/classroom/1/. Detailed explanations are illustrated\nin Appendix D and here we provide some highlights. First, our approach elicits a rich hierarchy. For\nexample, the taxicab problem is borrowed from Kahneman [8] and previous studies show that people\nusually ignore the base rate and report \u201880%\u2019. The imagined levels can be 41%\u219280%. We elicit a\nmuch richer level \u201c41%\u219250%\u219280%\u219212%\u219215%\u219220%\u201d. Second, the most sophisticated level\nmay fail to predict the least one. In the Taxicab problem, the correct \u201c41%\u201d supporters successfully\npredict the common wrong answer \u201c80%\u201d. However, they fail to predict the surprisingly wrong\nanswers \u201c12%,20%\u201d, which are in contrast successfully predicted by \u201c80%\u201d supporters. Our model\nis sufficiently general to allow this situation. Third, even for problems (like Go) without famous\nmistakes, our approach still works. Moreover, in the boundary question, we identify the correct\nanswer without any prior when only 3 respondents are correct.\n\n\nBased on the section, do the authors cite the creators of the existing assets that they use?"}]], "q4b": [[{"role": "user", "content": "The following is the experiments section of the paper you are reviewing:\n\n\nWe conduct four studies, study 1 (35 math problems), study 2 (30 Go problems), study 3 (44 general\nknowledge questions), and study 4 (43 Chinese character pronunciation questions).\n\nData collection All studies are performed by online questionnaires. We recruit the respondents by\nan online announcement13 or from an online platform that is similar to Amazon Mechanical Turk. We\nget respondents\u2019 consent for using and sharing their data for research. Respondents are asked not to\nsearch for the answers to the questions or communicate with other people. We allow the respondents\nto answer \u201cI do not know\u201d for all questions. Except for Go problems, all questionnaires use flat\npayment. We illustrate the data collection process in detail in Appendix A. We allow respondents\nto participate in more than one study because our algorithms analyze each question separately and\nindependently.\n\nData processing We merge answers which are the same, like \u20180.5\u2019 and \u201850%\u2019. We omit the answers\nthat are reported by less than (\u2264) 3% of respondents or one person. The remaining answers, excluding\n\u201cI do not know\u201d, form the answer set A whose size is |A|. We then construct the Answer-Prediction\nmatrix and perform our algorithms. Pseudo-codes are attached in Appendix B. Our algorithms do not\nrequire any prior or the respondents\u2019 expertise levels.\n\n3.1 Results\n\n12This may not be a very good assumption since i.i.d. samples can repeat but respondents usually do not\nrepeat their predictions. If we do not want this assumption, we can choose to only use the first prediction from\neach respondent (if there exists) to construct the answer-prediction matrix.\n\n13Many are students from top universities in China. See Appendix A for more details.\n\n8\n\n\fType\nMath\nGo\nGeneral knowledge\nChinese character\n\nTotal Our algorithm(Default) Our algorithm(Variant)\n\n35\n30\n44\n43\n\n29\n28\n41\n36\n\n29\n28\n41\n35\n\nPlurality voting\n24\n23\n35\n34\n\nTable 1: The number of questions our algorithms/baseline are correct.\n\n(a) the Monty Hall problem: you can select one\nclosed door of three. A prize, a car, is behind\none of the doors. The other two doors hide goats.\nAfter you have made your choice, Monty Hall\nwill open one of the remaining doors and show\nthat it does not contain the prize. He then asks\nyou if you would like to switch your choice to\nthe other unopened door. What is the probability\nto get the prize if you switch?\n\n(b) the Taxicab problem: 85% of taxis in this\ncity are green, the others are blue. A witness\nsees a blue taxi. She is usually correct with\nprobability 80%. What is the probability that\nthe taxi saw by the witness is blue?\n\n(c) Pick a move for black such that they can be\nalive.\n\n(d) Pick a move for black such that they can be\nalive by ko.\n\n(e) the boundary question: what river forms the\nboundary between North Korea and China?\n\n(f) the Middle Age New Year question: when\nwas the new year in middle age?\n\n(g) the pronunciation of \u7762\n\n(h) the pronunciation of \u6ec2\n\nFigure 4: The ranked answer-prediction matrices\n\n9\n\n2/31/21/32/31/21/3Answer34261413517146Prediction415080121520415080121520Answer160500008201200801619501104818000522130010218PredictionD3C1B2C2B1D3C1B2C2B1Answer62131091410042012115300002PredictionB8A8B6B7B8A8B6B7Answer112540630001230035PredictionYaluandDoomanYaluSonghuaYaluandDoomanYaluSonghuaAnswer33007410005PredictionApr1Dec25Jan1Apr1Dec25Jan1Answer15410028180633Predictionsui1ju1zhi4zhui1sui1ju1zhi4zhui1Answer115023161300210107Predictionpang1pang2pang1pang2Answer1511216Prediction\fWe compare our approach to the baseline, the plurality voting, regarding the accuracy of the top-\nranking answers. Both of the algorithms beat plurality voting for all studies and the default is slightly\nbetter. Among all 152 questions, in 138 questions, the variant algorithm outputs the same hierarchy as\nthe default algorithm. For other questions, the top-ranking type of the variant algorithm may contain\nmore than one answer. The top-ranking answer is the answer supported by more people among all\nanswers in the top-ranking type. In one question the variant is wrong but the default is correct, the\nvariant algorithm assigns both the correct answer and the incorrect plurality answer to the top-ranking\ntype, thus outputting the incorrect answer as the top-ranking answer.\n\nWe also compute the lack-of-fit index (Definition 2.6) of the algorithms and find that the questions\nthe algorithm outputs the correct answer have a smaller lack-of-fit thus fitting the thinking hierarchy\nmodel better. Therefore, we can use the lack-of-fit index as a reliability index of the algorithms.\n\nWe additionally pick several representative examples for each study (Figure 4) where the matrices\nare ranked by the default algorithm and the diagonal area modified like Example 1.1. In all of these\nexamples, the plurality is incorrect while our approach is correct. Results of other questions are\nillustrated at https://elicitation.info/classroom/1/. Detailed explanations are illustrated\nin Appendix D and here we provide some highlights. First, our approach elicits a rich hierarchy. For\nexample, the taxicab problem is borrowed from Kahneman [8] and previous studies show that people\nusually ignore the base rate and report \u201880%\u2019. The imagined levels can be 41%\u219280%. We elicit a\nmuch richer level \u201c41%\u219250%\u219280%\u219212%\u219215%\u219220%\u201d. Second, the most sophisticated level\nmay fail to predict the least one. In the Taxicab problem, the correct \u201c41%\u201d supporters successfully\npredict the common wrong answer \u201c80%\u201d. However, they fail to predict the surprisingly wrong\nanswers \u201c12%,20%\u201d, which are in contrast successfully predicted by \u201c80%\u201d supporters. Our model\nis sufficiently general to allow this situation. Third, even for problems (like Go) without famous\nmistakes, our approach still works. Moreover, in the boundary question, we identify the correct\nanswer without any prior when only 3 respondents are correct.\n\n\nBased on this section, do the authors use existing assets (e.g., code, data, models) that are not new contributions in their paper? Please start your answer with \"Yes\", \"No\", or \"Unsure\"."}, {"role": "user", "content": "The following is the experiments section of the paper you are reviewing:\n\n\nWe conduct four studies, study 1 (35 math problems), study 2 (30 Go problems), study 3 (44 general\nknowledge questions), and study 4 (43 Chinese character pronunciation questions).\n\nData collection All studies are performed by online questionnaires. We recruit the respondents by\nan online announcement13 or from an online platform that is similar to Amazon Mechanical Turk. We\nget respondents\u2019 consent for using and sharing their data for research. Respondents are asked not to\nsearch for the answers to the questions or communicate with other people. We allow the respondents\nto answer \u201cI do not know\u201d for all questions. Except for Go problems, all questionnaires use flat\npayment. We illustrate the data collection process in detail in Appendix A. We allow respondents\nto participate in more than one study because our algorithms analyze each question separately and\nindependently.\n\nData processing We merge answers which are the same, like \u20180.5\u2019 and \u201850%\u2019. We omit the answers\nthat are reported by less than (\u2264) 3% of respondents or one person. The remaining answers, excluding\n\u201cI do not know\u201d, form the answer set A whose size is |A|. We then construct the Answer-Prediction\nmatrix and perform our algorithms. Pseudo-codes are attached in Appendix B. Our algorithms do not\nrequire any prior or the respondents\u2019 expertise levels.\n\n3.1 Results\n\n12This may not be a very good assumption since i.i.d. samples can repeat but respondents usually do not\nrepeat their predictions. If we do not want this assumption, we can choose to only use the first prediction from\neach respondent (if there exists) to construct the answer-prediction matrix.\n\n13Many are students from top universities in China. See Appendix A for more details.\n\n8\n\n\fType\nMath\nGo\nGeneral knowledge\nChinese character\n\nTotal Our algorithm(Default) Our algorithm(Variant)\n\n35\n30\n44\n43\n\n29\n28\n41\n36\n\n29\n28\n41\n35\n\nPlurality voting\n24\n23\n35\n34\n\nTable 1: The number of questions our algorithms/baseline are correct.\n\n(a) the Monty Hall problem: you can select one\nclosed door of three. A prize, a car, is behind\none of the doors. The other two doors hide goats.\nAfter you have made your choice, Monty Hall\nwill open one of the remaining doors and show\nthat it does not contain the prize. He then asks\nyou if you would like to switch your choice to\nthe other unopened door. What is the probability\nto get the prize if you switch?\n\n(b) the Taxicab problem: 85% of taxis in this\ncity are green, the others are blue. A witness\nsees a blue taxi. She is usually correct with\nprobability 80%. What is the probability that\nthe taxi saw by the witness is blue?\n\n(c) Pick a move for black such that they can be\nalive.\n\n(d) Pick a move for black such that they can be\nalive by ko.\n\n(e) the boundary question: what river forms the\nboundary between North Korea and China?\n\n(f) the Middle Age New Year question: when\nwas the new year in middle age?\n\n(g) the pronunciation of \u7762\n\n(h) the pronunciation of \u6ec2\n\nFigure 4: The ranked answer-prediction matrices\n\n9\n\n2/31/21/32/31/21/3Answer34261413517146Prediction415080121520415080121520Answer160500008201200801619501104818000522130010218PredictionD3C1B2C2B1D3C1B2C2B1Answer62131091410042012115300002PredictionB8A8B6B7B8A8B6B7Answer112540630001230035PredictionYaluandDoomanYaluSonghuaYaluandDoomanYaluSonghuaAnswer33007410005PredictionApr1Dec25Jan1Apr1Dec25Jan1Answer15410028180633Predictionsui1ju1zhi4zhui1sui1ju1zhi4zhui1Answer115023161300210107Predictionpang1pang2pang1pang2Answer1511216Prediction\fWe compare our approach to the baseline, the plurality voting, regarding the accuracy of the top-\nranking answers. Both of the algorithms beat plurality voting for all studies and the default is slightly\nbetter. Among all 152 questions, in 138 questions, the variant algorithm outputs the same hierarchy as\nthe default algorithm. For other questions, the top-ranking type of the variant algorithm may contain\nmore than one answer. The top-ranking answer is the answer supported by more people among all\nanswers in the top-ranking type. In one question the variant is wrong but the default is correct, the\nvariant algorithm assigns both the correct answer and the incorrect plurality answer to the top-ranking\ntype, thus outputting the incorrect answer as the top-ranking answer.\n\nWe also compute the lack-of-fit index (Definition 2.6) of the algorithms and find that the questions\nthe algorithm outputs the correct answer have a smaller lack-of-fit thus fitting the thinking hierarchy\nmodel better. Therefore, we can use the lack-of-fit index as a reliability index of the algorithms.\n\nWe additionally pick several representative examples for each study (Figure 4) where the matrices\nare ranked by the default algorithm and the diagonal area modified like Example 1.1. In all of these\nexamples, the plurality is incorrect while our approach is correct. Results of other questions are\nillustrated at https://elicitation.info/classroom/1/. Detailed explanations are illustrated\nin Appendix D and here we provide some highlights. First, our approach elicits a rich hierarchy. For\nexample, the taxicab problem is borrowed from Kahneman [8] and previous studies show that people\nusually ignore the base rate and report \u201880%\u2019. The imagined levels can be 41%\u219280%. We elicit a\nmuch richer level \u201c41%\u219250%\u219280%\u219212%\u219215%\u219220%\u201d. Second, the most sophisticated level\nmay fail to predict the least one. In the Taxicab problem, the correct \u201c41%\u201d supporters successfully\npredict the common wrong answer \u201c80%\u201d. However, they fail to predict the surprisingly wrong\nanswers \u201c12%,20%\u201d, which are in contrast successfully predicted by \u201c80%\u201d supporters. Our model\nis sufficiently general to allow this situation. Third, even for problems (like Go) without famous\nmistakes, our approach still works. Moreover, in the boundary question, we identify the correct\nanswer without any prior when only 3 respondents are correct.\n\n\nBased on the section, do the authors mention the licenses of the existing assets that they use?"}]], "q4c": [[{"role": "user", "content": "The following is the abstract section of the paper you are reviewing:\n\n\nWhen we use the wisdom of the crowds, we usually rank the answers according to\ntheir popularity, especially when we cannot verify the answers. However, this can\nbe very dangerous when the majority make systematic mistakes. A fundamental\nquestion arises: can we build a hierarchy among the answers without any prior\nwhere the higher-ranking answers, which may not be supported by the majority,\nare from more sophisticated people? To address the question, we propose 1) a\nnovel model to describe people\u2019s thinking hierarchy; 2) two algorithms to learn\nthe thinking hierarchy without any prior; 3) a novel open-response based crowd-\nsourcing approach based on the above theoretic framework. In addition to theoretic\njustifications, we conduct four empirical crowdsourcing studies and show that a)\nthe accuracy of the top-ranking answers learned by our approach is much higher\nthan that of plurality voting (In one question, the plurality answer is supported by\n74 respondents but the correct answer is only supported by 3 respondents. Our\napproach ranks the correct answer the highest without any prior); b) our model\nhas a high goodness-of-fit, especially for the questions where our top-ranking\nanswer is correct. To the best of our knowledge, we are the first to propose a\nthinking hierarchy model with empirical validations in the general problem-solving\nscenarios; and the first to propose a practical open-response based crowdsourcing\napproach that beats plurality voting without any prior.\n\n1\n\n\nBased on this abstract, do the authors curate/release new assets (e.g., code, data, models)? Please start your answer with \"Yes\", \"No\", or \"Unsure\"."}, {"role": "user", "content": "The following is the experiments section of the paper you are reviewing:\n\n\nWe conduct four studies, study 1 (35 math problems), study 2 (30 Go problems), study 3 (44 general\nknowledge questions), and study 4 (43 Chinese character pronunciation questions).\n\nData collection All studies are performed by online questionnaires. We recruit the respondents by\nan online announcement13 or from an online platform that is similar to Amazon Mechanical Turk. We\nget respondents\u2019 consent for using and sharing their data for research. Respondents are asked not to\nsearch for the answers to the questions or communicate with other people. We allow the respondents\nto answer \u201cI do not know\u201d for all questions. Except for Go problems, all questionnaires use flat\npayment. We illustrate the data collection process in detail in Appendix A. We allow respondents\nto participate in more than one study because our algorithms analyze each question separately and\nindependently.\n\nData processing We merge answers which are the same, like \u20180.5\u2019 and \u201850%\u2019. We omit the answers\nthat are reported by less than (\u2264) 3% of respondents or one person. The remaining answers, excluding\n\u201cI do not know\u201d, form the answer set A whose size is |A|. We then construct the Answer-Prediction\nmatrix and perform our algorithms. Pseudo-codes are attached in Appendix B. Our algorithms do not\nrequire any prior or the respondents\u2019 expertise levels.\n\n3.1 Results\n\n12This may not be a very good assumption since i.i.d. samples can repeat but respondents usually do not\nrepeat their predictions. If we do not want this assumption, we can choose to only use the first prediction from\neach respondent (if there exists) to construct the answer-prediction matrix.\n\n13Many are students from top universities in China. See Appendix A for more details.\n\n8\n\n\fType\nMath\nGo\nGeneral knowledge\nChinese character\n\nTotal Our algorithm(Default) Our algorithm(Variant)\n\n35\n30\n44\n43\n\n29\n28\n41\n36\n\n29\n28\n41\n35\n\nPlurality voting\n24\n23\n35\n34\n\nTable 1: The number of questions our algorithms/baseline are correct.\n\n(a) the Monty Hall problem: you can select one\nclosed door of three. A prize, a car, is behind\none of the doors. The other two doors hide goats.\nAfter you have made your choice, Monty Hall\nwill open one of the remaining doors and show\nthat it does not contain the prize. He then asks\nyou if you would like to switch your choice to\nthe other unopened door. What is the probability\nto get the prize if you switch?\n\n(b) the Taxicab problem: 85% of taxis in this\ncity are green, the others are blue. A witness\nsees a blue taxi. She is usually correct with\nprobability 80%. What is the probability that\nthe taxi saw by the witness is blue?\n\n(c) Pick a move for black such that they can be\nalive.\n\n(d) Pick a move for black such that they can be\nalive by ko.\n\n(e) the boundary question: what river forms the\nboundary between North Korea and China?\n\n(f) the Middle Age New Year question: when\nwas the new year in middle age?\n\n(g) the pronunciation of \u7762\n\n(h) the pronunciation of \u6ec2\n\nFigure 4: The ranked answer-prediction matrices\n\n9\n\n2/31/21/32/31/21/3Answer34261413517146Prediction415080121520415080121520Answer160500008201200801619501104818000522130010218PredictionD3C1B2C2B1D3C1B2C2B1Answer62131091410042012115300002PredictionB8A8B6B7B8A8B6B7Answer112540630001230035PredictionYaluandDoomanYaluSonghuaYaluandDoomanYaluSonghuaAnswer33007410005PredictionApr1Dec25Jan1Apr1Dec25Jan1Answer15410028180633Predictionsui1ju1zhi4zhui1sui1ju1zhi4zhui1Answer115023161300210107Predictionpang1pang2pang1pang2Answer1511216Prediction\fWe compare our approach to the baseline, the plurality voting, regarding the accuracy of the top-\nranking answers. Both of the algorithms beat plurality voting for all studies and the default is slightly\nbetter. Among all 152 questions, in 138 questions, the variant algorithm outputs the same hierarchy as\nthe default algorithm. For other questions, the top-ranking type of the variant algorithm may contain\nmore than one answer. The top-ranking answer is the answer supported by more people among all\nanswers in the top-ranking type. In one question the variant is wrong but the default is correct, the\nvariant algorithm assigns both the correct answer and the incorrect plurality answer to the top-ranking\ntype, thus outputting the incorrect answer as the top-ranking answer.\n\nWe also compute the lack-of-fit index (Definition 2.6) of the algorithms and find that the questions\nthe algorithm outputs the correct answer have a smaller lack-of-fit thus fitting the thinking hierarchy\nmodel better. Therefore, we can use the lack-of-fit index as a reliability index of the algorithms.\n\nWe additionally pick several representative examples for each study (Figure 4) where the matrices\nare ranked by the default algorithm and the diagonal area modified like Example 1.1. In all of these\nexamples, the plurality is incorrect while our approach is correct. Results of other questions are\nillustrated at https://elicitation.info/classroom/1/. Detailed explanations are illustrated\nin Appendix D and here we provide some highlights. First, our approach elicits a rich hierarchy. For\nexample, the taxicab problem is borrowed from Kahneman [8] and previous studies show that people\nusually ignore the base rate and report \u201880%\u2019. The imagined levels can be 41%\u219280%. We elicit a\nmuch richer level \u201c41%\u219250%\u219280%\u219212%\u219215%\u219220%\u201d. Second, the most sophisticated level\nmay fail to predict the least one. In the Taxicab problem, the correct \u201c41%\u201d supporters successfully\npredict the common wrong answer \u201c80%\u201d. However, they fail to predict the surprisingly wrong\nanswers \u201c12%,20%\u201d, which are in contrast successfully predicted by \u201c80%\u201d supporters. Our model\nis sufficiently general to allow this situation. Third, even for problems (like Go) without famous\nmistakes, our approach still works. Moreover, in the boundary question, we identify the correct\nanswer without any prior when only 3 respondents are correct.\n\n\nBased on this section, do the authors include any new assets either in the supplemental material or as a URL?"}]], "q4d": [[{"role": "user", "content": "The following is the abstract section of the paper you are reviewing:\n\n\nWhen we use the wisdom of the crowds, we usually rank the answers according to\ntheir popularity, especially when we cannot verify the answers. However, this can\nbe very dangerous when the majority make systematic mistakes. A fundamental\nquestion arises: can we build a hierarchy among the answers without any prior\nwhere the higher-ranking answers, which may not be supported by the majority,\nare from more sophisticated people? To address the question, we propose 1) a\nnovel model to describe people\u2019s thinking hierarchy; 2) two algorithms to learn\nthe thinking hierarchy without any prior; 3) a novel open-response based crowd-\nsourcing approach based on the above theoretic framework. In addition to theoretic\njustifications, we conduct four empirical crowdsourcing studies and show that a)\nthe accuracy of the top-ranking answers learned by our approach is much higher\nthan that of plurality voting (In one question, the plurality answer is supported by\n74 respondents but the correct answer is only supported by 3 respondents. Our\napproach ranks the correct answer the highest without any prior); b) our model\nhas a high goodness-of-fit, especially for the questions where our top-ranking\nanswer is correct. To the best of our knowledge, we are the first to propose a\nthinking hierarchy model with empirical validations in the general problem-solving\nscenarios; and the first to propose a practical open-response based crowdsourcing\napproach that beats plurality voting without any prior.\n\n1\n\n\nBased on this abstract, do the authors curate/release new assets (e.g., code, data, models)? Please start your answer with \"Yes\", \"No\", or \"Unsure\"."}, {"role": "user", "content": "The following is the experiments section of the paper you are reviewing:\n\n\nWe conduct four studies, study 1 (35 math problems), study 2 (30 Go problems), study 3 (44 general\nknowledge questions), and study 4 (43 Chinese character pronunciation questions).\n\nData collection All studies are performed by online questionnaires. We recruit the respondents by\nan online announcement13 or from an online platform that is similar to Amazon Mechanical Turk. We\nget respondents\u2019 consent for using and sharing their data for research. Respondents are asked not to\nsearch for the answers to the questions or communicate with other people. We allow the respondents\nto answer \u201cI do not know\u201d for all questions. Except for Go problems, all questionnaires use flat\npayment. We illustrate the data collection process in detail in Appendix A. We allow respondents\nto participate in more than one study because our algorithms analyze each question separately and\nindependently.\n\nData processing We merge answers which are the same, like \u20180.5\u2019 and \u201850%\u2019. We omit the answers\nthat are reported by less than (\u2264) 3% of respondents or one person. The remaining answers, excluding\n\u201cI do not know\u201d, form the answer set A whose size is |A|. We then construct the Answer-Prediction\nmatrix and perform our algorithms. Pseudo-codes are attached in Appendix B. Our algorithms do not\nrequire any prior or the respondents\u2019 expertise levels.\n\n3.1 Results\n\n12This may not be a very good assumption since i.i.d. samples can repeat but respondents usually do not\nrepeat their predictions. If we do not want this assumption, we can choose to only use the first prediction from\neach respondent (if there exists) to construct the answer-prediction matrix.\n\n13Many are students from top universities in China. See Appendix A for more details.\n\n8\n\n\fType\nMath\nGo\nGeneral knowledge\nChinese character\n\nTotal Our algorithm(Default) Our algorithm(Variant)\n\n35\n30\n44\n43\n\n29\n28\n41\n36\n\n29\n28\n41\n35\n\nPlurality voting\n24\n23\n35\n34\n\nTable 1: The number of questions our algorithms/baseline are correct.\n\n(a) the Monty Hall problem: you can select one\nclosed door of three. A prize, a car, is behind\none of the doors. The other two doors hide goats.\nAfter you have made your choice, Monty Hall\nwill open one of the remaining doors and show\nthat it does not contain the prize. He then asks\nyou if you would like to switch your choice to\nthe other unopened door. What is the probability\nto get the prize if you switch?\n\n(b) the Taxicab problem: 85% of taxis in this\ncity are green, the others are blue. A witness\nsees a blue taxi. She is usually correct with\nprobability 80%. What is the probability that\nthe taxi saw by the witness is blue?\n\n(c) Pick a move for black such that they can be\nalive.\n\n(d) Pick a move for black such that they can be\nalive by ko.\n\n(e) the boundary question: what river forms the\nboundary between North Korea and China?\n\n(f) the Middle Age New Year question: when\nwas the new year in middle age?\n\n(g) the pronunciation of \u7762\n\n(h) the pronunciation of \u6ec2\n\nFigure 4: The ranked answer-prediction matrices\n\n9\n\n2/31/21/32/31/21/3Answer34261413517146Prediction415080121520415080121520Answer160500008201200801619501104818000522130010218PredictionD3C1B2C2B1D3C1B2C2B1Answer62131091410042012115300002PredictionB8A8B6B7B8A8B6B7Answer112540630001230035PredictionYaluandDoomanYaluSonghuaYaluandDoomanYaluSonghuaAnswer33007410005PredictionApr1Dec25Jan1Apr1Dec25Jan1Answer15410028180633Predictionsui1ju1zhi4zhui1sui1ju1zhi4zhui1Answer115023161300210107Predictionpang1pang2pang1pang2Answer1511216Prediction\fWe compare our approach to the baseline, the plurality voting, regarding the accuracy of the top-\nranking answers. Both of the algorithms beat plurality voting for all studies and the default is slightly\nbetter. Among all 152 questions, in 138 questions, the variant algorithm outputs the same hierarchy as\nthe default algorithm. For other questions, the top-ranking type of the variant algorithm may contain\nmore than one answer. The top-ranking answer is the answer supported by more people among all\nanswers in the top-ranking type. In one question the variant is wrong but the default is correct, the\nvariant algorithm assigns both the correct answer and the incorrect plurality answer to the top-ranking\ntype, thus outputting the incorrect answer as the top-ranking answer.\n\nWe also compute the lack-of-fit index (Definition 2.6) of the algorithms and find that the questions\nthe algorithm outputs the correct answer have a smaller lack-of-fit thus fitting the thinking hierarchy\nmodel better. Therefore, we can use the lack-of-fit index as a reliability index of the algorithms.\n\nWe additionally pick several representative examples for each study (Figure 4) where the matrices\nare ranked by the default algorithm and the diagonal area modified like Example 1.1. In all of these\nexamples, the plurality is incorrect while our approach is correct. Results of other questions are\nillustrated at https://elicitation.info/classroom/1/. Detailed explanations are illustrated\nin Appendix D and here we provide some highlights. First, our approach elicits a rich hierarchy. For\nexample, the taxicab problem is borrowed from Kahneman [8] and previous studies show that people\nusually ignore the base rate and report \u201880%\u2019. The imagined levels can be 41%\u219280%. We elicit a\nmuch richer level \u201c41%\u219250%\u219280%\u219212%\u219215%\u219220%\u201d. Second, the most sophisticated level\nmay fail to predict the least one. In the Taxicab problem, the correct \u201c41%\u201d supporters successfully\npredict the common wrong answer \u201c80%\u201d. However, they fail to predict the surprisingly wrong\nanswers \u201c12%,20%\u201d, which are in contrast successfully predicted by \u201c80%\u201d supporters. Our model\nis sufficiently general to allow this situation. Third, even for problems (like Go) without famous\nmistakes, our approach still works. Moreover, in the boundary question, we identify the correct\nanswer without any prior when only 3 respondents are correct.\n\n\nBased on this section, do the authors discuss whether and how consent was obtained from people whose data the authors are using/curating?"}]], "q4e": [[{"role": "user", "content": "The following is the abstract section of the paper you are reviewing:\n\n\nWhen we use the wisdom of the crowds, we usually rank the answers according to\ntheir popularity, especially when we cannot verify the answers. However, this can\nbe very dangerous when the majority make systematic mistakes. A fundamental\nquestion arises: can we build a hierarchy among the answers without any prior\nwhere the higher-ranking answers, which may not be supported by the majority,\nare from more sophisticated people? To address the question, we propose 1) a\nnovel model to describe people\u2019s thinking hierarchy; 2) two algorithms to learn\nthe thinking hierarchy without any prior; 3) a novel open-response based crowd-\nsourcing approach based on the above theoretic framework. In addition to theoretic\njustifications, we conduct four empirical crowdsourcing studies and show that a)\nthe accuracy of the top-ranking answers learned by our approach is much higher\nthan that of plurality voting (In one question, the plurality answer is supported by\n74 respondents but the correct answer is only supported by 3 respondents. Our\napproach ranks the correct answer the highest without any prior); b) our model\nhas a high goodness-of-fit, especially for the questions where our top-ranking\nanswer is correct. To the best of our knowledge, we are the first to propose a\nthinking hierarchy model with empirical validations in the general problem-solving\nscenarios; and the first to propose a practical open-response based crowdsourcing\napproach that beats plurality voting without any prior.\n\n1\n\n\nBased on this abstract, do the authors curate/release new assets (e.g., code, data, models)? Please start your answer with \"Yes\", \"No\", or \"Unsure\"."}, {"role": "user", "content": "The following is the experiments section of the paper you are reviewing:\n\n\nWe conduct four studies, study 1 (35 math problems), study 2 (30 Go problems), study 3 (44 general\nknowledge questions), and study 4 (43 Chinese character pronunciation questions).\n\nData collection All studies are performed by online questionnaires. We recruit the respondents by\nan online announcement13 or from an online platform that is similar to Amazon Mechanical Turk. We\nget respondents\u2019 consent for using and sharing their data for research. Respondents are asked not to\nsearch for the answers to the questions or communicate with other people. We allow the respondents\nto answer \u201cI do not know\u201d for all questions. Except for Go problems, all questionnaires use flat\npayment. We illustrate the data collection process in detail in Appendix A. We allow respondents\nto participate in more than one study because our algorithms analyze each question separately and\nindependently.\n\nData processing We merge answers which are the same, like \u20180.5\u2019 and \u201850%\u2019. We omit the answers\nthat are reported by less than (\u2264) 3% of respondents or one person. The remaining answers, excluding\n\u201cI do not know\u201d, form the answer set A whose size is |A|. We then construct the Answer-Prediction\nmatrix and perform our algorithms. Pseudo-codes are attached in Appendix B. Our algorithms do not\nrequire any prior or the respondents\u2019 expertise levels.\n\n3.1 Results\n\n12This may not be a very good assumption since i.i.d. samples can repeat but respondents usually do not\nrepeat their predictions. If we do not want this assumption, we can choose to only use the first prediction from\neach respondent (if there exists) to construct the answer-prediction matrix.\n\n13Many are students from top universities in China. See Appendix A for more details.\n\n8\n\n\fType\nMath\nGo\nGeneral knowledge\nChinese character\n\nTotal Our algorithm(Default) Our algorithm(Variant)\n\n35\n30\n44\n43\n\n29\n28\n41\n36\n\n29\n28\n41\n35\n\nPlurality voting\n24\n23\n35\n34\n\nTable 1: The number of questions our algorithms/baseline are correct.\n\n(a) the Monty Hall problem: you can select one\nclosed door of three. A prize, a car, is behind\none of the doors. The other two doors hide goats.\nAfter you have made your choice, Monty Hall\nwill open one of the remaining doors and show\nthat it does not contain the prize. He then asks\nyou if you would like to switch your choice to\nthe other unopened door. What is the probability\nto get the prize if you switch?\n\n(b) the Taxicab problem: 85% of taxis in this\ncity are green, the others are blue. A witness\nsees a blue taxi. She is usually correct with\nprobability 80%. What is the probability that\nthe taxi saw by the witness is blue?\n\n(c) Pick a move for black such that they can be\nalive.\n\n(d) Pick a move for black such that they can be\nalive by ko.\n\n(e) the boundary question: what river forms the\nboundary between North Korea and China?\n\n(f) the Middle Age New Year question: when\nwas the new year in middle age?\n\n(g) the pronunciation of \u7762\n\n(h) the pronunciation of \u6ec2\n\nFigure 4: The ranked answer-prediction matrices\n\n9\n\n2/31/21/32/31/21/3Answer34261413517146Prediction415080121520415080121520Answer160500008201200801619501104818000522130010218PredictionD3C1B2C2B1D3C1B2C2B1Answer62131091410042012115300002PredictionB8A8B6B7B8A8B6B7Answer112540630001230035PredictionYaluandDoomanYaluSonghuaYaluandDoomanYaluSonghuaAnswer33007410005PredictionApr1Dec25Jan1Apr1Dec25Jan1Answer15410028180633Predictionsui1ju1zhi4zhui1sui1ju1zhi4zhui1Answer115023161300210107Predictionpang1pang2pang1pang2Answer1511216Prediction\fWe compare our approach to the baseline, the plurality voting, regarding the accuracy of the top-\nranking answers. Both of the algorithms beat plurality voting for all studies and the default is slightly\nbetter. Among all 152 questions, in 138 questions, the variant algorithm outputs the same hierarchy as\nthe default algorithm. For other questions, the top-ranking type of the variant algorithm may contain\nmore than one answer. The top-ranking answer is the answer supported by more people among all\nanswers in the top-ranking type. In one question the variant is wrong but the default is correct, the\nvariant algorithm assigns both the correct answer and the incorrect plurality answer to the top-ranking\ntype, thus outputting the incorrect answer as the top-ranking answer.\n\nWe also compute the lack-of-fit index (Definition 2.6) of the algorithms and find that the questions\nthe algorithm outputs the correct answer have a smaller lack-of-fit thus fitting the thinking hierarchy\nmodel better. Therefore, we can use the lack-of-fit index as a reliability index of the algorithms.\n\nWe additionally pick several representative examples for each study (Figure 4) where the matrices\nare ranked by the default algorithm and the diagonal area modified like Example 1.1. In all of these\nexamples, the plurality is incorrect while our approach is correct. Results of other questions are\nillustrated at https://elicitation.info/classroom/1/. Detailed explanations are illustrated\nin Appendix D and here we provide some highlights. First, our approach elicits a rich hierarchy. For\nexample, the taxicab problem is borrowed from Kahneman [8] and previous studies show that people\nusually ignore the base rate and report \u201880%\u2019. The imagined levels can be 41%\u219280%. We elicit a\nmuch richer level \u201c41%\u219250%\u219280%\u219212%\u219215%\u219220%\u201d. Second, the most sophisticated level\nmay fail to predict the least one. In the Taxicab problem, the correct \u201c41%\u201d supporters successfully\npredict the common wrong answer \u201c80%\u201d. However, they fail to predict the surprisingly wrong\nanswers \u201c12%,20%\u201d, which are in contrast successfully predicted by \u201c80%\u201d supporters. Our model\nis sufficiently general to allow this situation. Third, even for problems (like Go) without famous\nmistakes, our approach still works. Moreover, in the boundary question, we identify the correct\nanswer without any prior when only 3 respondents are correct.\n\n\nBased on this section, do the authors discuss whether the data used/curated contains personally identifiable information or offensive content?"}]], "q5a": [[{"role": "user", "content": "The following is the abstract of the paper you are reviewing:\n\n\nWhen we use the wisdom of the crowds, we usually rank the answers according to\ntheir popularity, especially when we cannot verify the answers. However, this can\nbe very dangerous when the majority make systematic mistakes. A fundamental\nquestion arises: can we build a hierarchy among the answers without any prior\nwhere the higher-ranking answers, which may not be supported by the majority,\nare from more sophisticated people? To address the question, we propose 1) a\nnovel model to describe people\u2019s thinking hierarchy; 2) two algorithms to learn\nthe thinking hierarchy without any prior; 3) a novel open-response based crowd-\nsourcing approach based on the above theoretic framework. In addition to theoretic\njustifications, we conduct four empirical crowdsourcing studies and show that a)\nthe accuracy of the top-ranking answers learned by our approach is much higher\nthan that of plurality voting (In one question, the plurality answer is supported by\n74 respondents but the correct answer is only supported by 3 respondents. Our\napproach ranks the correct answer the highest without any prior); b) our model\nhas a high goodness-of-fit, especially for the questions where our top-ranking\nanswer is correct. To the best of our knowledge, we are the first to propose a\nthinking hierarchy model with empirical validations in the general problem-solving\nscenarios; and the first to propose a practical open-response based crowdsourcing\napproach that beats plurality voting without any prior.\n\n1\n\n\nBased on this abstract, do the authors use crowdsourcing or conduct research with human subjects? Please start your answer with \"Yes\", \"No\", or \"Unsure\"."}, {"role": "user", "content": "The following is the experiments section of the paper you are reviewing:\n\n\nWe conduct four studies, study 1 (35 math problems), study 2 (30 Go problems), study 3 (44 general\nknowledge questions), and study 4 (43 Chinese character pronunciation questions).\n\nData collection All studies are performed by online questionnaires. We recruit the respondents by\nan online announcement13 or from an online platform that is similar to Amazon Mechanical Turk. We\nget respondents\u2019 consent for using and sharing their data for research. Respondents are asked not to\nsearch for the answers to the questions or communicate with other people. We allow the respondents\nto answer \u201cI do not know\u201d for all questions. Except for Go problems, all questionnaires use flat\npayment. We illustrate the data collection process in detail in Appendix A. We allow respondents\nto participate in more than one study because our algorithms analyze each question separately and\nindependently.\n\nData processing We merge answers which are the same, like \u20180.5\u2019 and \u201850%\u2019. We omit the answers\nthat are reported by less than (\u2264) 3% of respondents or one person. The remaining answers, excluding\n\u201cI do not know\u201d, form the answer set A whose size is |A|. We then construct the Answer-Prediction\nmatrix and perform our algorithms. Pseudo-codes are attached in Appendix B. Our algorithms do not\nrequire any prior or the respondents\u2019 expertise levels.\n\n3.1 Results\n\n12This may not be a very good assumption since i.i.d. samples can repeat but respondents usually do not\nrepeat their predictions. If we do not want this assumption, we can choose to only use the first prediction from\neach respondent (if there exists) to construct the answer-prediction matrix.\n\n13Many are students from top universities in China. See Appendix A for more details.\n\n8\n\n\fType\nMath\nGo\nGeneral knowledge\nChinese character\n\nTotal Our algorithm(Default) Our algorithm(Variant)\n\n35\n30\n44\n43\n\n29\n28\n41\n36\n\n29\n28\n41\n35\n\nPlurality voting\n24\n23\n35\n34\n\nTable 1: The number of questions our algorithms/baseline are correct.\n\n(a) the Monty Hall problem: you can select one\nclosed door of three. A prize, a car, is behind\none of the doors. The other two doors hide goats.\nAfter you have made your choice, Monty Hall\nwill open one of the remaining doors and show\nthat it does not contain the prize. He then asks\nyou if you would like to switch your choice to\nthe other unopened door. What is the probability\nto get the prize if you switch?\n\n(b) the Taxicab problem: 85% of taxis in this\ncity are green, the others are blue. A witness\nsees a blue taxi. She is usually correct with\nprobability 80%. What is the probability that\nthe taxi saw by the witness is blue?\n\n(c) Pick a move for black such that they can be\nalive.\n\n(d) Pick a move for black such that they can be\nalive by ko.\n\n(e) the boundary question: what river forms the\nboundary between North Korea and China?\n\n(f) the Middle Age New Year question: when\nwas the new year in middle age?\n\n(g) the pronunciation of \u7762\n\n(h) the pronunciation of \u6ec2\n\nFigure 4: The ranked answer-prediction matrices\n\n9\n\n2/31/21/32/31/21/3Answer34261413517146Prediction415080121520415080121520Answer160500008201200801619501104818000522130010218PredictionD3C1B2C2B1D3C1B2C2B1Answer62131091410042012115300002PredictionB8A8B6B7B8A8B6B7Answer112540630001230035PredictionYaluandDoomanYaluSonghuaYaluandDoomanYaluSonghuaAnswer33007410005PredictionApr1Dec25Jan1Apr1Dec25Jan1Answer15410028180633Predictionsui1ju1zhi4zhui1sui1ju1zhi4zhui1Answer115023161300210107Predictionpang1pang2pang1pang2Answer1511216Prediction\fWe compare our approach to the baseline, the plurality voting, regarding the accuracy of the top-\nranking answers. Both of the algorithms beat plurality voting for all studies and the default is slightly\nbetter. Among all 152 questions, in 138 questions, the variant algorithm outputs the same hierarchy as\nthe default algorithm. For other questions, the top-ranking type of the variant algorithm may contain\nmore than one answer. The top-ranking answer is the answer supported by more people among all\nanswers in the top-ranking type. In one question the variant is wrong but the default is correct, the\nvariant algorithm assigns both the correct answer and the incorrect plurality answer to the top-ranking\ntype, thus outputting the incorrect answer as the top-ranking answer.\n\nWe also compute the lack-of-fit index (Definition 2.6) of the algorithms and find that the questions\nthe algorithm outputs the correct answer have a smaller lack-of-fit thus fitting the thinking hierarchy\nmodel better. Therefore, we can use the lack-of-fit index as a reliability index of the algorithms.\n\nWe additionally pick several representative examples for each study (Figure 4) where the matrices\nare ranked by the default algorithm and the diagonal area modified like Example 1.1. In all of these\nexamples, the plurality is incorrect while our approach is correct. Results of other questions are\nillustrated at https://elicitation.info/classroom/1/. Detailed explanations are illustrated\nin Appendix D and here we provide some highlights. First, our approach elicits a rich hierarchy. For\nexample, the taxicab problem is borrowed from Kahneman [8] and previous studies show that people\nusually ignore the base rate and report \u201880%\u2019. The imagined levels can be 41%\u219280%. We elicit a\nmuch richer level \u201c41%\u219250%\u219280%\u219212%\u219215%\u219220%\u201d. Second, the most sophisticated level\nmay fail to predict the least one. In the Taxicab problem, the correct \u201c41%\u201d supporters successfully\npredict the common wrong answer \u201c80%\u201d. However, they fail to predict the surprisingly wrong\nanswers \u201c12%,20%\u201d, which are in contrast successfully predicted by \u201c80%\u201d supporters. Our model\nis sufficiently general to allow this situation. Third, even for problems (like Go) without famous\nmistakes, our approach still works. Moreover, in the boundary question, we identify the correct\nanswer without any prior when only 3 respondents are correct.\n\n\nBased on this section, do the authors include the full text of instructions given to participants and screenshots, if applicable?"}]], "q5b": [[{"role": "user", "content": "The following is the abstract of the paper you are reviewing:\n\n\nWhen we use the wisdom of the crowds, we usually rank the answers according to\ntheir popularity, especially when we cannot verify the answers. However, this can\nbe very dangerous when the majority make systematic mistakes. A fundamental\nquestion arises: can we build a hierarchy among the answers without any prior\nwhere the higher-ranking answers, which may not be supported by the majority,\nare from more sophisticated people? To address the question, we propose 1) a\nnovel model to describe people\u2019s thinking hierarchy; 2) two algorithms to learn\nthe thinking hierarchy without any prior; 3) a novel open-response based crowd-\nsourcing approach based on the above theoretic framework. In addition to theoretic\njustifications, we conduct four empirical crowdsourcing studies and show that a)\nthe accuracy of the top-ranking answers learned by our approach is much higher\nthan that of plurality voting (In one question, the plurality answer is supported by\n74 respondents but the correct answer is only supported by 3 respondents. Our\napproach ranks the correct answer the highest without any prior); b) our model\nhas a high goodness-of-fit, especially for the questions where our top-ranking\nanswer is correct. To the best of our knowledge, we are the first to propose a\nthinking hierarchy model with empirical validations in the general problem-solving\nscenarios; and the first to propose a practical open-response based crowdsourcing\napproach that beats plurality voting without any prior.\n\n1\n\n\nBased on this abstract, do the authors use crowdsourcing or conduct research with human subjects? Please start your answer with \"Yes\", \"No\", or \"Unsure\"."}, {"role": "user", "content": "The following is the experiments section of the paper you are reviewing:\n\n\nWe conduct four studies, study 1 (35 math problems), study 2 (30 Go problems), study 3 (44 general\nknowledge questions), and study 4 (43 Chinese character pronunciation questions).\n\nData collection All studies are performed by online questionnaires. We recruit the respondents by\nan online announcement13 or from an online platform that is similar to Amazon Mechanical Turk. We\nget respondents\u2019 consent for using and sharing their data for research. Respondents are asked not to\nsearch for the answers to the questions or communicate with other people. We allow the respondents\nto answer \u201cI do not know\u201d for all questions. Except for Go problems, all questionnaires use flat\npayment. We illustrate the data collection process in detail in Appendix A. We allow respondents\nto participate in more than one study because our algorithms analyze each question separately and\nindependently.\n\nData processing We merge answers which are the same, like \u20180.5\u2019 and \u201850%\u2019. We omit the answers\nthat are reported by less than (\u2264) 3% of respondents or one person. The remaining answers, excluding\n\u201cI do not know\u201d, form the answer set A whose size is |A|. We then construct the Answer-Prediction\nmatrix and perform our algorithms. Pseudo-codes are attached in Appendix B. Our algorithms do not\nrequire any prior or the respondents\u2019 expertise levels.\n\n3.1 Results\n\n12This may not be a very good assumption since i.i.d. samples can repeat but respondents usually do not\nrepeat their predictions. If we do not want this assumption, we can choose to only use the first prediction from\neach respondent (if there exists) to construct the answer-prediction matrix.\n\n13Many are students from top universities in China. See Appendix A for more details.\n\n8\n\n\fType\nMath\nGo\nGeneral knowledge\nChinese character\n\nTotal Our algorithm(Default) Our algorithm(Variant)\n\n35\n30\n44\n43\n\n29\n28\n41\n36\n\n29\n28\n41\n35\n\nPlurality voting\n24\n23\n35\n34\n\nTable 1: The number of questions our algorithms/baseline are correct.\n\n(a) the Monty Hall problem: you can select one\nclosed door of three. A prize, a car, is behind\none of the doors. The other two doors hide goats.\nAfter you have made your choice, Monty Hall\nwill open one of the remaining doors and show\nthat it does not contain the prize. He then asks\nyou if you would like to switch your choice to\nthe other unopened door. What is the probability\nto get the prize if you switch?\n\n(b) the Taxicab problem: 85% of taxis in this\ncity are green, the others are blue. A witness\nsees a blue taxi. She is usually correct with\nprobability 80%. What is the probability that\nthe taxi saw by the witness is blue?\n\n(c) Pick a move for black such that they can be\nalive.\n\n(d) Pick a move for black such that they can be\nalive by ko.\n\n(e) the boundary question: what river forms the\nboundary between North Korea and China?\n\n(f) the Middle Age New Year question: when\nwas the new year in middle age?\n\n(g) the pronunciation of \u7762\n\n(h) the pronunciation of \u6ec2\n\nFigure 4: The ranked answer-prediction matrices\n\n9\n\n2/31/21/32/31/21/3Answer34261413517146Prediction415080121520415080121520Answer160500008201200801619501104818000522130010218PredictionD3C1B2C2B1D3C1B2C2B1Answer62131091410042012115300002PredictionB8A8B6B7B8A8B6B7Answer112540630001230035PredictionYaluandDoomanYaluSonghuaYaluandDoomanYaluSonghuaAnswer33007410005PredictionApr1Dec25Jan1Apr1Dec25Jan1Answer15410028180633Predictionsui1ju1zhi4zhui1sui1ju1zhi4zhui1Answer115023161300210107Predictionpang1pang2pang1pang2Answer1511216Prediction\fWe compare our approach to the baseline, the plurality voting, regarding the accuracy of the top-\nranking answers. Both of the algorithms beat plurality voting for all studies and the default is slightly\nbetter. Among all 152 questions, in 138 questions, the variant algorithm outputs the same hierarchy as\nthe default algorithm. For other questions, the top-ranking type of the variant algorithm may contain\nmore than one answer. The top-ranking answer is the answer supported by more people among all\nanswers in the top-ranking type. In one question the variant is wrong but the default is correct, the\nvariant algorithm assigns both the correct answer and the incorrect plurality answer to the top-ranking\ntype, thus outputting the incorrect answer as the top-ranking answer.\n\nWe also compute the lack-of-fit index (Definition 2.6) of the algorithms and find that the questions\nthe algorithm outputs the correct answer have a smaller lack-of-fit thus fitting the thinking hierarchy\nmodel better. Therefore, we can use the lack-of-fit index as a reliability index of the algorithms.\n\nWe additionally pick several representative examples for each study (Figure 4) where the matrices\nare ranked by the default algorithm and the diagonal area modified like Example 1.1. In all of these\nexamples, the plurality is incorrect while our approach is correct. Results of other questions are\nillustrated at https://elicitation.info/classroom/1/. Detailed explanations are illustrated\nin Appendix D and here we provide some highlights. First, our approach elicits a rich hierarchy. For\nexample, the taxicab problem is borrowed from Kahneman [8] and previous studies show that people\nusually ignore the base rate and report \u201880%\u2019. The imagined levels can be 41%\u219280%. We elicit a\nmuch richer level \u201c41%\u219250%\u219280%\u219212%\u219215%\u219220%\u201d. Second, the most sophisticated level\nmay fail to predict the least one. In the Taxicab problem, the correct \u201c41%\u201d supporters successfully\npredict the common wrong answer \u201c80%\u201d. However, they fail to predict the surprisingly wrong\nanswers \u201c12%,20%\u201d, which are in contrast successfully predicted by \u201c80%\u201d supporters. Our model\nis sufficiently general to allow this situation. Third, even for problems (like Go) without famous\nmistakes, our approach still works. Moreover, in the boundary question, we identify the correct\nanswer without any prior when only 3 respondents are correct.\n\n\nBased on this section, do the authors describe any potential participant risks, with links to Institutional Review Board (IRB) approvals, if applicable?"}]], "q5c": [[{"role": "user", "content": "The following is the abstract of the paper you are reviewing:\n\n\nWhen we use the wisdom of the crowds, we usually rank the answers according to\ntheir popularity, especially when we cannot verify the answers. However, this can\nbe very dangerous when the majority make systematic mistakes. A fundamental\nquestion arises: can we build a hierarchy among the answers without any prior\nwhere the higher-ranking answers, which may not be supported by the majority,\nare from more sophisticated people? To address the question, we propose 1) a\nnovel model to describe people\u2019s thinking hierarchy; 2) two algorithms to learn\nthe thinking hierarchy without any prior; 3) a novel open-response based crowd-\nsourcing approach based on the above theoretic framework. In addition to theoretic\njustifications, we conduct four empirical crowdsourcing studies and show that a)\nthe accuracy of the top-ranking answers learned by our approach is much higher\nthan that of plurality voting (In one question, the plurality answer is supported by\n74 respondents but the correct answer is only supported by 3 respondents. Our\napproach ranks the correct answer the highest without any prior); b) our model\nhas a high goodness-of-fit, especially for the questions where our top-ranking\nanswer is correct. To the best of our knowledge, we are the first to propose a\nthinking hierarchy model with empirical validations in the general problem-solving\nscenarios; and the first to propose a practical open-response based crowdsourcing\napproach that beats plurality voting without any prior.\n\n1\n\n\nBased on this abstract, do the authors use crowdsourcing or conduct research with human subjects? Please start your answer with \"Yes\", \"No\", or \"Unsure\"."}, {"role": "user", "content": "The following is the experiments section of the paper you are reviewing:\n\n\nWe conduct four studies, study 1 (35 math problems), study 2 (30 Go problems), study 3 (44 general\nknowledge questions), and study 4 (43 Chinese character pronunciation questions).\n\nData collection All studies are performed by online questionnaires. We recruit the respondents by\nan online announcement13 or from an online platform that is similar to Amazon Mechanical Turk. We\nget respondents\u2019 consent for using and sharing their data for research. Respondents are asked not to\nsearch for the answers to the questions or communicate with other people. We allow the respondents\nto answer \u201cI do not know\u201d for all questions. Except for Go problems, all questionnaires use flat\npayment. We illustrate the data collection process in detail in Appendix A. We allow respondents\nto participate in more than one study because our algorithms analyze each question separately and\nindependently.\n\nData processing We merge answers which are the same, like \u20180.5\u2019 and \u201850%\u2019. We omit the answers\nthat are reported by less than (\u2264) 3% of respondents or one person. The remaining answers, excluding\n\u201cI do not know\u201d, form the answer set A whose size is |A|. We then construct the Answer-Prediction\nmatrix and perform our algorithms. Pseudo-codes are attached in Appendix B. Our algorithms do not\nrequire any prior or the respondents\u2019 expertise levels.\n\n3.1 Results\n\n12This may not be a very good assumption since i.i.d. samples can repeat but respondents usually do not\nrepeat their predictions. If we do not want this assumption, we can choose to only use the first prediction from\neach respondent (if there exists) to construct the answer-prediction matrix.\n\n13Many are students from top universities in China. See Appendix A for more details.\n\n8\n\n\fType\nMath\nGo\nGeneral knowledge\nChinese character\n\nTotal Our algorithm(Default) Our algorithm(Variant)\n\n35\n30\n44\n43\n\n29\n28\n41\n36\n\n29\n28\n41\n35\n\nPlurality voting\n24\n23\n35\n34\n\nTable 1: The number of questions our algorithms/baseline are correct.\n\n(a) the Monty Hall problem: you can select one\nclosed door of three. A prize, a car, is behind\none of the doors. The other two doors hide goats.\nAfter you have made your choice, Monty Hall\nwill open one of the remaining doors and show\nthat it does not contain the prize. He then asks\nyou if you would like to switch your choice to\nthe other unopened door. What is the probability\nto get the prize if you switch?\n\n(b) the Taxicab problem: 85% of taxis in this\ncity are green, the others are blue. A witness\nsees a blue taxi. She is usually correct with\nprobability 80%. What is the probability that\nthe taxi saw by the witness is blue?\n\n(c) Pick a move for black such that they can be\nalive.\n\n(d) Pick a move for black such that they can be\nalive by ko.\n\n(e) the boundary question: what river forms the\nboundary between North Korea and China?\n\n(f) the Middle Age New Year question: when\nwas the new year in middle age?\n\n(g) the pronunciation of \u7762\n\n(h) the pronunciation of \u6ec2\n\nFigure 4: The ranked answer-prediction matrices\n\n9\n\n2/31/21/32/31/21/3Answer34261413517146Prediction415080121520415080121520Answer160500008201200801619501104818000522130010218PredictionD3C1B2C2B1D3C1B2C2B1Answer62131091410042012115300002PredictionB8A8B6B7B8A8B6B7Answer112540630001230035PredictionYaluandDoomanYaluSonghuaYaluandDoomanYaluSonghuaAnswer33007410005PredictionApr1Dec25Jan1Apr1Dec25Jan1Answer15410028180633Predictionsui1ju1zhi4zhui1sui1ju1zhi4zhui1Answer115023161300210107Predictionpang1pang2pang1pang2Answer1511216Prediction\fWe compare our approach to the baseline, the plurality voting, regarding the accuracy of the top-\nranking answers. Both of the algorithms beat plurality voting for all studies and the default is slightly\nbetter. Among all 152 questions, in 138 questions, the variant algorithm outputs the same hierarchy as\nthe default algorithm. For other questions, the top-ranking type of the variant algorithm may contain\nmore than one answer. The top-ranking answer is the answer supported by more people among all\nanswers in the top-ranking type. In one question the variant is wrong but the default is correct, the\nvariant algorithm assigns both the correct answer and the incorrect plurality answer to the top-ranking\ntype, thus outputting the incorrect answer as the top-ranking answer.\n\nWe also compute the lack-of-fit index (Definition 2.6) of the algorithms and find that the questions\nthe algorithm outputs the correct answer have a smaller lack-of-fit thus fitting the thinking hierarchy\nmodel better. Therefore, we can use the lack-of-fit index as a reliability index of the algorithms.\n\nWe additionally pick several representative examples for each study (Figure 4) where the matrices\nare ranked by the default algorithm and the diagonal area modified like Example 1.1. In all of these\nexamples, the plurality is incorrect while our approach is correct. Results of other questions are\nillustrated at https://elicitation.info/classroom/1/. Detailed explanations are illustrated\nin Appendix D and here we provide some highlights. First, our approach elicits a rich hierarchy. For\nexample, the taxicab problem is borrowed from Kahneman [8] and previous studies show that people\nusually ignore the base rate and report \u201880%\u2019. The imagined levels can be 41%\u219280%. We elicit a\nmuch richer level \u201c41%\u219250%\u219280%\u219212%\u219215%\u219220%\u201d. Second, the most sophisticated level\nmay fail to predict the least one. In the Taxicab problem, the correct \u201c41%\u201d supporters successfully\npredict the common wrong answer \u201c80%\u201d. However, they fail to predict the surprisingly wrong\nanswers \u201c12%,20%\u201d, which are in contrast successfully predicted by \u201c80%\u201d supporters. Our model\nis sufficiently general to allow this situation. Third, even for problems (like Go) without famous\nmistakes, our approach still works. Moreover, in the boundary question, we identify the correct\nanswer without any prior when only 3 respondents are correct.\n\n\nBased on this section, do the authors include the estimated hourly wage paid to participants and the total amount spent on participant compensation?"}]]}}